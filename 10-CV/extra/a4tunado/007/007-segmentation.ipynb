{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana Image Masking Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/carvana-image-masking-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n",
      "2.8.0\n",
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(cv2.__version__)\n",
    "print(imageio.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем исходные изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "IMG_HEIGHT = 320\n",
    "IMG_WIDTH = 480\n",
    "\n",
    "train_img_paths = sorted(glob('data/carvana/train/*.jpg'))\n",
    "train_mask_paths = sorted(glob('data/carvana/train_masks/*.gif'))\n",
    "\n",
    "def load_image(path):\n",
    "    # используем imageio, тк cv2 \n",
    "    # не поддерживает загрузку .gif\n",
    "    img = imageio.imread(path)\n",
    "    return cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "def binarise(img):\n",
    "    thr, result = cv2.threshold(img, -1, 1, cv2.THRESH_OTSU)\n",
    "    return result\n",
    "\n",
    "train_imgs = np.array(\n",
    "    [load_image(path) for path in train_img_paths])\n",
    "\n",
    "train_masks = np.array(\n",
    "    [binarise(load_image(path)) for path in train_mask_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Входное изображение')\n",
    "plt.imshow(train_imgs[1]);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Маска сегментации')\n",
    "plt.imshow(train_masks[1], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализируем архитектуру U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задаем функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTH = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + SMOOTH) / (tf.reduce_sum(y_true_f + y_pred_f) + SMOOTH)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.2 * tf.keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запускаем процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(lr=1e-4),\n",
    "              bce_dice_loss,\n",
    "              metrics=[tf.keras.losses.binary_crossentropy, dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_imgs, train_masks, batch_size=4, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = sorted(glob('data/carvana/test/*.jpg'))\n",
    "\n",
    "def test_img_generator(test_paths):\n",
    "    for path in test_paths:\n",
    "        yield np.array([load_image(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_img_generator(test_paths))\n",
    "pred = np.squeeze(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем результат на тестовом семпле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_SAMPLES = 3\n",
    "SAMPLES_OFFSET = 3\n",
    "\n",
    "fig = plt.figure(0, figsize=(16, 16))\n",
    "\n",
    "for i in range(SHOW_SAMPLES):\n",
    "    plt.subplot(SHOW_SAMPLES, 2, 2*i+1)\n",
    "    plt.imshow(load_image(test_paths[SAMPLES_OFFSET+i]))\n",
    "    plt.subplot(SHOW_SAMPLES, 2, 2*i+2)\n",
    "    plt.imshow(pred[SAMPLES_OFFSET+i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
