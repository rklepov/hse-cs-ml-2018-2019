{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Seedlings Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/plant-seedlings-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image(path, dsize=(128, 128)):\n",
    "    ''' Ресайз и нормировка изображения '''\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)[:, :, ::-1].astype(np.float32)\n",
    "    img -= [83.693283426971817, 72.796752160982763, 51.88953774401763]\n",
    "    return cv2.resize(img, dsize)  # приводим все изображения к единому размеру\n",
    "\n",
    "def read_train_labels(path = 'train'):\n",
    "    ''' Загрузка списка файлов для обучения '''\n",
    "    labels = []\n",
    "    for entry in glob.glob(os.path.join(path, '*', '*.png')):\n",
    "        parts = entry.split(os.path.sep)\n",
    "        labels.append((parts[-2], entry))\n",
    "    df = pd.DataFrame(data=labels, columns=('label', 'path'))\n",
    "    df['label'] = df['label'].astype('category')\n",
    "    return df\n",
    "\n",
    "def load_test_data(path = 'test', dsize = (128, 128)):\n",
    "    ''' Загружаем тестовые изображения '''\n",
    "    paths = list(glob.glob(os.path.join(path, '*.png')))\n",
    "    X = [_process_image(entry) for entry in paths]\n",
    "    y = [path.split(os.path.sep)[-1] for path in paths]\n",
    "    return np.array(X), y\n",
    "\n",
    "def _to_categorical(label, categories):\n",
    "    ''' Onehot encoding '''\n",
    "    onehot = np.zeros(len(categories), np.float32)\n",
    "    onehot[categories[label]] = 1\n",
    "    return onehot\n",
    "\n",
    "def generator(df, categories, batch_size=24, dsize = (128, 128)):\n",
    "    ''' Возвращает батч картинок и классов '''\n",
    "    while True:\n",
    "        # перемешиваем данные на очередной эпохе\n",
    "        df = shuffle(df)\n",
    "        # итерируем по батчам \n",
    "        for i in range(len(df) // batch_size):\n",
    "            X, y = [], []\n",
    "            # итерируем по элементам в батче\n",
    "            for j in range(i * batch_size, (i + 1) * batch_size):\n",
    "                X.append(_process_image(df.values[j][1]))\n",
    "                y.append(_to_categorical(df.values[j][0], categories))\n",
    "            yield np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем данные для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all.zip               sample_submission.csv \u001b[34mtrain\u001b[m\u001b[m\r\n",
      "plant.ipynb           submission.csv        train.zip\r\n",
      "plant.tar.gz          \u001b[34mtest\u001b[m\u001b[m\r\n",
      "plant_weights.h5      test.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_train_labels()\n",
    "\n",
    "categories = dict((label, i) for i, label \n",
    "                  in enumerate(sorted(df['label'].cat.categories)))\n",
    "\n",
    "inv_categories = dict((v, k) for k, v in categories.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектура сверточной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.kaggle.com/miklgr500/keras-simple-model-0-97103-best-public-score\n",
    "\n",
    "# полносвязный слой\n",
    "def dense_set(inp_layer, n, activation, drop_rate=0):\n",
    "    dp = keras.layers.Dropout(drop_rate)(inp_layer)\n",
    "    dns = keras.layers.Dense(n)(dp)\n",
    "    bn = keras.layers.BatchNormalization(axis=-1)(dns)\n",
    "    act = keras.layers.Activation(activation=activation)(bn)\n",
    "    return act\n",
    "\n",
    "# сверточный слой\n",
    "def conv_layer(feature_batch, feature_map, kernel_size=(3, 3),strides=(1,1), zp_flag=False):\n",
    "    if zp_flag:\n",
    "        zp = keras.layers.ZeroPadding2D((1,1))(feature_batch)\n",
    "    else:\n",
    "        zp = feature_batch\n",
    "    conv = keras.layers.Conv2D(filters=feature_map, kernel_size=kernel_size, strides=strides)(zp)\n",
    "    bn = keras.layers.BatchNormalization(axis=3)(conv)\n",
    "    act = keras.layers.LeakyReLU(1/10)(bn)\n",
    "    return act\n",
    "\n",
    "# создаем модель\n",
    "def get_model():\n",
    "    inp_img = keras.layers.Input(shape=(128, 128, 3))\n",
    "\n",
    "    # 128\n",
    "    conv1 = conv_layer(inp_img, 64, zp_flag=False)\n",
    "    conv2 = conv_layer(conv1, 64, zp_flag=False)\n",
    "    mp1 = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv2)\n",
    "    # 64\n",
    "    conv3 = conv_layer(mp1, 128, zp_flag=False)\n",
    "    conv4 = conv_layer(conv3, 128, zp_flag=False)\n",
    "    mp2 = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv4)\n",
    "    # 32\n",
    "    conv7 = conv_layer(mp2, 256, zp_flag=False)\n",
    "    conv8 = conv_layer(conv7, 256, zp_flag=False)\n",
    "    conv9 = conv_layer(conv8, 256, zp_flag=False)\n",
    "    mp3 = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n",
    "    # 1\n",
    "    # dense layers\n",
    "    flt = keras.layers.Flatten()(mp3)\n",
    "    ds1 = dense_set(flt, 128, activation='tanh')\n",
    "    out = dense_set(ds1, 12, activation='softmax')\n",
    "\n",
    "    model = keras.models.Model(inputs=inp_img, outputs=out)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.5 * 1e-2, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=optimizer,\n",
    "                   metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запускаем обучение последнего слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Выделяем 30% на валидацию\n",
    "train_df, test_df = train_test_split(df,\n",
    "                                     test_size=0.33,\n",
    "                                     random_state=123)\n",
    "\n",
    "# мониторинг процесса обучения\n",
    "lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n",
    "                                              factor=0.1,\n",
    "                                              epsilon=1e-5, \n",
    "                                              patience=5, \n",
    "                                              verbose=1)\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('plant_weights.h5',\n",
    "                                             save_best_only=True,\n",
    "                                             verbose=1)\n",
    "callbacks = [lr_reduce, checkpoint]\n",
    "\n",
    "# закружаем валидационные изображения в память\n",
    "test_gen = generator(test_df, categories, batch_size = len(test_df))\n",
    "test_X, test_y = next(test_gen)\n",
    "\n",
    "# запускаем процесс обучения модели\n",
    "batch_size = 128\n",
    "train_generator = generator(train_df, categories, batch_size = batch_size)\n",
    "steps_per_epoch = len(train_df) / batch_size\n",
    "\n",
    "if os.path.exists('plant_weights.h5'):\n",
    "    model.load_weights('plant_weights.h5')\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch,\n",
    "                    epochs=30,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_X, test_y),\n",
    "                    callbacks=[lr_reduce, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оцениваем качество предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "actual = np.argmax(test_y, -1)\n",
    "predicted = np.argmax(model.predict(test_X), -1)\n",
    "\n",
    "print(classification_report(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применяем обученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем модель и загружаем веса\n",
    "model = get_model()\n",
    "model.load_weights(filepath='plant_weights.h5')\n",
    "\n",
    "# загружаем тестовые изображения\n",
    "test_imgs, test_path = load_test_data()\n",
    "\n",
    "# применяем модель и сохраняем результат\n",
    "pred = np.argmax(model.predict(test_imgs, verbose=1), axis=-1)\n",
    "pred_df = pd.DataFrame({'file': test_path,\n",
    "                        'species': [inv_categories[p] for p in pred]})\n",
    "pred_df.to_csv('submission.csv', index=False, header=True)\n",
    "\n",
    "# F1=0.79219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
