{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A training example in Pytorch\n",
    "## Introduction\n",
    "### Task\n",
    "В этом ноутбуке мы научим нейронную сеть выполнять простую задачу. Это будет задача классификации. Классификация в основном означает нахождение *decision boundary* в пространстве вещественных чисел. В целях понятности мы будем работать с 2D-примером: *decision boundary* будет круг. Точнее, единичный круг на плоскости.\n",
    "\n",
    "![](unitycircle.png)\n",
    "### Sampling\n",
    "Будем генерировать точки $(x_1,x_2)$ для классификации, и их класс $y$. Настоящая разделяющая функция будет $y=1_{x_1^2+x_2^2<1}$.\n",
    "\n",
    "Чтобы иметь сбалансированный набор данных с примерно одинаковым количеством точек в каждом классе, мы будем производить выборку равномерно по полярным координатам, в пределах круга с центром 0 и радиусом 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# если гпу у вас несколько укажите номер гпу, которую хотите использовать\n",
    "# номер свободной можно посмотреть с помощью nvidia-smi в терминале\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points(n):\n",
    "    # returns (X,Y), where X of shape (n,2) is the numpy array of points and Y is the (n) array of classes\n",
    "    \n",
    "    radius = np.random.uniform(low=0,high=2,size=n).reshape(-1,1) # uniform radius between 0 and 2\n",
    "    angle = np.random.uniform(low=0,high=2*np.pi,size=n).reshape(-1,1) # uniform angle\n",
    "    x1 = radius*np.cos(angle)\n",
    "    x2=radius*np.sin(angle)\n",
    "    y = (radius<1).astype(int).reshape(-1)\n",
    "    x = np.concatenate([x1,x2],axis=1)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data\n",
    "trainx,trainy = sample_points(10000)\n",
    "valx,valy = sample_points(500)\n",
    "testx,testy = sample_points(500)\n",
    "\n",
    "print(trainx.shape,trainy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель будет многослойным перцептроном с одним скрытым слоем и выходом размера 2, так как у нас есть два класса. Поскольку это задача бинарной классификации, мы могли бы также использовать только один выход и нулевой порог, но мы будем использовать два, чтобы проиллюстрировать использование кросс-энтропийной функции потерь в pytorch (на следующей неделе вы увидите, как использовать BinaryCrossEntropy для такой задачи) ,\n",
    "\n",
    "Многослойный перцептрон не может выучить круговую границу, но может представлять границу - полигон, число сторон которого равно числу нейронов на скрытом слое. Например, с 6 скрытыми нейронами модель может вычислить гексагональную границу, которая приближается к единичному кругу, например:\n",
    "![](hexagon.png)\n",
    "\n",
    "Обратите внимание, что оптимальная точность (accuracy), ожидаемая от гексагона, аппроксимирующего единичный круг, составляет около **xxxx**. Конечно, обученная модель не будет вычислять фактический гексагон из-за активации, которая не является порогом, и свободы весов конечного слоя. На самом деле мы можем ожидать *лучшую* точность, чем эта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_hidden_MLP(n_hidden_neurons):\n",
    "    return nn.Sequential(nn.Linear(2,n_hidden_neurons),nn.ReLU(),nn.Linear(n_hidden_neurons,2))\n",
    "model1 = generate_single_hidden_MLP(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы обучить нашу модель, нам нужно будет кормить ее тензорами. Давайте преобразуем наши сгенерированные массивы NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = torch.from_numpy(trainx).float()\n",
    "valx = torch.from_numpy(valx).float()\n",
    "testx = torch.from_numpy(testx).float()\n",
    "trainy = torch.from_numpy(trainy)\n",
    "valy = torch.from_numpy(valy)\n",
    "testy = torch.from_numpy(testy)\n",
    "print(trainx.type(),trainy.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы определимся с нашей тренировочной рутиной. Возникает вопрос о том, выполнять ли тренировку на CPU or GPU. Лучше всего использовать flag переменную, которую вы будете устанавливать, когда будете выполнять обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_routine(net,dataset,n_iters,gpu):\n",
    "    # organize the data\n",
    "    train_data,train_labels,val_data,val_labels = dataset\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(),lr=0.01)\n",
    "    \n",
    "    # use the flag\n",
    "    if gpu:\n",
    "        train_data,train_labels = train_data.cuda(),train_labels.cuda()\n",
    "        val_data,val_labels = val_data.cuda(),val_labels.cuda()\n",
    "        net = net.cuda() # the network parameters also need to be on the gpu !\n",
    "        print(\"Using GPU\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "    for i in range(n_iters):\n",
    "        # forward pass\n",
    "        train_output = net(train_data)\n",
    "        train_loss = criterion(train_output,train_labels)\n",
    "        # backward pass and optimization\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Once every 100 iterations, print statistics\n",
    "        if i%100==0:\n",
    "            print(\"At iteration\",i)\n",
    "            # compute the accuracy of the prediction\n",
    "            train_prediction = train_output.cpu().detach().argmax(dim=1)\n",
    "            train_accuracy = (train_prediction.numpy()==train_labels.numpy()).mean() \n",
    "            # Now for the validation set\n",
    "            val_output = net(val_data)\n",
    "            val_loss = criterion(val_output,val_labels)\n",
    "            # compute the accuracy of the prediction\n",
    "            val_prediction = val_output.cpu().detach().argmax(dim=1)\n",
    "            val_accuracy = (val_prediction.numpy()==val_labels.numpy()).mean() \n",
    "            print(\"Training loss :\",train_loss.cpu().detach().numpy())\n",
    "            print(\"Training accuracy :\",train_accuracy)\n",
    "            print(\"Validation loss :\",val_loss.cpu().detach().numpy())\n",
    "            print(\"Validation accuracy :\",val_accuracy)\n",
    "    \n",
    "    net = net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = trainx,trainy,valx,valy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = False\n",
    "gpu = gpu and torch.cuda.is_available() # to know if you actually can use the GPU\n",
    "\n",
    "training_routine(model1,dataset,10000,gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try with 3 hidden neurons.\n",
    "model2 = generate_single_hidden_MLP(3) \n",
    "training_routine(model2,dataset,10000,gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model2(testx).argmax(dim=1).detach().numpy()\n",
    "green = testx.numpy()[np.where(out==1)]\n",
    "red = testx.numpy()[np.where(out==0)]\n",
    "print(green.shape,red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model,datapoints):\n",
    "    out = model(datapoints).argmax(dim=1).detach().numpy()\n",
    "    green = datapoints.numpy()[np.where(out==1)]\n",
    "    red = datapoints.numpy()[np.where(out==0)]\n",
    "\n",
    "    circle1 = plt.Circle((0, 0), 1, color='y')\n",
    "    circle2 = plt.Circle((0, 0), 1, color='b',fill=False)\n",
    "\n",
    "    fig, ax = plt.subplots() # note we must use plt.subplots, not plt.subplot\n",
    "    # (or if you have an existing figure)\n",
    "    # fig = plt.gcf()\n",
    "    # ax = fig.gca()\n",
    "    plt.xlim((-2,2))\n",
    "    plt.ylim((-2,2))\n",
    "\n",
    "    pos_values = plt.scatter(x=green[:,0],y=green[:,1], color='g',)\n",
    "    neg_values = plt.scatter(x=red[:,0],y=red[:,1], color='r',)\n",
    "\n",
    "    ax.add_artist(circle1)\n",
    "    ax.add_artist(circle2)\n",
    "    ax.add_artist(pos_values)\n",
    "    ax.add_artist(neg_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model(model1,testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model(model2,testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = generate_single_hidden_MLP(2) \n",
    "training_routine(model3,dataset,10000,gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model(model3,testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
