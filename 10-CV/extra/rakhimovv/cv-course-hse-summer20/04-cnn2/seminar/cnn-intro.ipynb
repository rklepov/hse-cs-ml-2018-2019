{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep learning for computer vision\n",
    "\n",
    "Научимся тренировать сверточные нейронные сети для распознования изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny ImageNet dataset\n",
    "Будем практиковаться с Tiny Image Net датасетом\n",
    "* 100k изображений размера 3x64x64\n",
    "* 200 разных классов: змеи, пауки, кошки, грузовики, и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# если у вас больше 1й видеокарты, полезно бывает ограничить видимость\n",
    "# до 1й в случае если не собираетесь распараллеливать обучение\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '#номер карты'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiny_imagenet\n",
    "tiny_imagenet.download(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"tiny-imagenet-200\"\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    os.path.join(dataset_root, \"train\"),\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2768, 0.2689, 0.2819])\n",
    "    ]))\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    os.path.join(dataset_root, \"val\"),\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2768, 0.2689, 0.2819])\n",
    "    ]))\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image examples ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<tr>\n",
    "    <td> <img src=\"tinyim3.png\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "    <td> <img src=\"tinyim2.png\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "</tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"tiniim.png\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a network\n",
    "\n",
    "Простые нейронные сети с наслоением стандартных слоев могут быть реализованы с помощью `torch.nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a special module that converts [batch, channel, w, h] to [batch, units]\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала начнем с полносвязной сетью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('flatten', Flatten())\n",
    "model.add_module('dense1', nn.Linear(3 * 64 * 64, 512))\n",
    "model.add_module('dense1_relu', nn.ReLU())\n",
    "model.add_module('dense2', nn.Linear(512, 256))\n",
    "model.add_module('dense2_relu', nn.ReLU())\n",
    "model.add_module('dense3', nn.Linear(256, 128))\n",
    "model.add_module('dense3_relu', nn.ReLU())\n",
    "model.add_module('dropout', nn.Dropout(0.05))\n",
    "model.add_module('dense4', nn.Linear(128, 64))\n",
    "model.add_module('dense3_relu', nn.ReLU())\n",
    "model.add_module('logits', nn.Linear(64, 200)) # logits на 200 классов\n",
    "\n",
    "# эквивалентно, но слои без имен\n",
    "# model == nn.Sequential(\n",
    "#     Flatten(),\n",
    "#     nn.Linear(3 * 64 * 64, 1064),\n",
    "#     nn.Linear(3 * 64 * 64, 1064),\n",
    "#     ...\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Напишем тренировочную и тестовую \"рутину\"\n",
    "\n",
    "Ниже приводится пример! того как можно разбить на различные функции процесс обучения и валидации, вместо того чтобы писать один большой громоздкий цикл, как в предыдущих семинарах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(batch, model, device=torch.device('cpu')):\n",
    "    data, target = batch\n",
    "    \n",
    "    # закидываем данные и модель на один и тот же device\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # включаем train mode (обязательно например при наличии dropout, batch_norm и т.д.)\n",
    "    model.train()\n",
    "    \n",
    "    logits = model(data)\n",
    "    loss = F.cross_entropy(logits, target)\n",
    "    \n",
    "    # loss.item() эквивалентно loss.detach().cpu().numpy()\n",
    "    logs = {'train_ce_loss': loss.item()}\n",
    "    \n",
    "    return {'loss': loss, 'log': logs}\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scheduler=None, device=torch.device('cpu')):\n",
    "    logs = []\n",
    "    for batch in tqdm(loader):\n",
    "        output = training_step(batch, model, device)\n",
    "        loss = output['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        logs.append(output['log'])\n",
    "    return logs\n",
    "\n",
    "def train_epoch_end(logs):\n",
    "    avg_train_ce_loss = np.mean([x['train_ce_loss'] for x in logs])\n",
    "    return {'avg_train_ce_loss': avg_train_ce_loss}\n",
    "\n",
    "def validation_step(batch, model, device=torch.device('cpu')):\n",
    "    data, target = batch\n",
    "    \n",
    "    # закидываем данные и модель на один и тот же device\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # включаем eval mode (обязательно например при наличии dropout, batch_norm и т.д.)\n",
    "    model.eval()\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "    inference_time_per_batch = time.perf_counter() - start_time\n",
    "    \n",
    "    pred = logits.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "    correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "    log = {'correct': correct, 'inference_time_per_batch': inference_time_per_batch, 'amount': pred.shape[0]}\n",
    "    return {'log': log}\n",
    "\n",
    "def val_one_epoch(model, loader, device=torch.device('cpu')):\n",
    "    logs = []\n",
    "    for batch in tqdm(loader):\n",
    "        output = validation_step(batch, model, device)\n",
    "        logs.append(output['log'])\n",
    "    return logs\n",
    "        \n",
    "def validation_epoch_end(logs):\n",
    "    total_amount = np.sum([x['amount'] for x in logs])\n",
    "    total_correct = np.sum([x['correct'] for x in logs])\n",
    "    accuracy = 100 * total_correct / total_amount \n",
    "    avg_inference_time_per_batch = np.mean([x['inference_time_per_batch'] for x in logs])\n",
    "    return {'val_accuracy (%)': accuracy, 'avg_inference_time_per_batch (sec)': avg_inference_time_per_batch}\n",
    "    \n",
    "def configure_optimizers(model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "    scheduler = None\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer, scheduler = configure_optimizers(model)\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    train_logs = train_one_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(train_epoch_end(train_logs))\n",
    "    val_logs = val_one_epoch(model, val_loader, device)\n",
    "    print(validation_epoch_end(val_logs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не ждите все 100 эпох. Если видите, что точность на валидации не растет в течение 5-20 эпох - можете остановить процесс.\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "### Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test stage:\")\n",
    "val_logs = val_one_epoch(model, val_loader)\n",
    "print(validation_epoch_end(val_logs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task I: small convolution net\n",
    "### Первый шаг\n",
    "\n",
    "Давайте создадим маленькую сверточную сеть с примерно следующей архитектурой:\n",
    "* Input layer\n",
    "* 3x3 convolution with 128 filters and _ReLU_ activation\n",
    "* 2x2 pooling (or set previous convolution stride to 2)\n",
    "* Flatten\n",
    "* Dense layer with 1024 neurons and _ReLU_ activation\n",
    "* 30% dropout\n",
    "* Output dense layer.\n",
    "\n",
    "\n",
    "__Convolutional layers__ отдельный класс слоев в торче со своим набором параметров\n",
    "\n",
    "__`...`__\n",
    "\n",
    "__`model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)) # convolution`__\n",
    "\n",
    "__`model.add_module('pool1', nn.MaxPool2d(2)) # max pooling 2x2`__\n",
    "\n",
    "__`...`__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer, scheduler = configure_optimizers(model)\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    train_logs = train_one_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(train_epoch_end(train_logs))\n",
    "    val_logs = val_one_epoch(model, val_loader, device)\n",
    "    print(validation_epoch_end(val_logs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "__Hint:__ Если не хотите вручную считать размеры линейного слоя, можете сначала указать любой размер и запустить. Вы увидите нечто похожее:\n",
    "\n",
    "__`RuntimeError: size mismatch, m1: [5 x 1960], m2: [1 x 64] at /some/long/path/to/torch/operation`__\n",
    "\n",
    "Видите число __1960__? Это как раз нужный вам размер входа линейного слоя.\n",
    "\n",
    "## Task 2: adding normalization\n",
    "\n",
    "* Добавьте batch norm (со стандартными параметрами) между convolution и ReLU\n",
    "  * nn.BatchNorm*d (1d for dense, 2d for conv)\n",
    "  * обычно его добавляют после linear/conv но перед нелинейностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer, scheduler = configure_optimizers(model)\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    train_logs = train_one_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(train_epoch_end(train_logs))\n",
    "    val_logs = val_one_epoch(model, val_loader, device)\n",
    "    print(validation_epoch_end(val_logs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "## Task 3: Data Augmentation\n",
    "\n",
    "** Augmenti - A spell used to produce water from a wand (Harry Potter Wiki) **\n",
    "\n",
    "<img src=\"HagridsHut_PM_B6C28_Hagrid_sHutFireHarryFang.jpg\" style=\"width:80%\">\n",
    "\n",
    "В торче есть инструмент полезный для data preprocessing и augmentation.\n",
    "\n",
    "С помощью него мы определяем следующий пайплайн:\n",
    "* поворачиваем изображение (augmentation)\n",
    "* рандомно делает горизонтальный флип (augmentation)\n",
    "* нормализуем изображение (preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время тестирования нам не нужны аугментации, а нужно оставить только __нормализацию__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "dataset_root = \"tiny-imagenet-200\"\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    os.path.join(dataset_root, \"train\"),\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2768, 0.2689, 0.2819])\n",
    "    ]))\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    os.path.join(dataset_root, \"val\"),\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2768, 0.2689, 0.2819])\n",
    "    ]))\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer, scheduler = configure_optimizers(model)\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    train_logs = train_one_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(train_epoch_end(train_logs))\n",
    "    val_logs = val_one_epoch(model, val_loader, device)\n",
    "    print(validation_epoch_end(val_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
