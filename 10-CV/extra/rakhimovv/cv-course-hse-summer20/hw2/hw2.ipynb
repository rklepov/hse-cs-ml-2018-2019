{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Гомография (Проективная геометрия)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем делать демо приложения для дополненной реальности.\n",
    "\n",
    "Вдохновлено: https://www.indiegogo.com/projects/lifeprint-photos-that-come-to-life-in-your-hands/\n",
    "\n",
    "Для этого нам понадобится:\n",
    "1. Найти ключевые точки на изоброжении, получить их дескрипторы и найти соответствия (матчи) между точками на двух изображениях\n",
    "2. С помощью \"сматченных\" точек посчитать гомографию, чтобы можно было деформировать изображения\n",
    "\n",
    "Максимально можно получить 50 баллов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "import skimage.color\n",
    "import skimage.feature\n",
    "import skimage.transform\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Поиск ключевых точек и матчей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся FAST детектором (он достаточно простой, погуглите про него информацию) для поиска ключевых точек, вместо рассмотренного на лекции детектора Харриса.\n",
    "\n",
    "**Вопрос:** В чем основное отличие детектора FAST от Харриса? Является ли он быстрее?\n",
    "    \n",
    "**Ваш ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы нашли ключевые точки нам нужно их сматчить. Мы воспользуемся алгоритмом BRIEF (он достаточно простой, погуглите про него информацию), который присваивает бинарный дексриптор каждой ключевой точке. Для матчинга точек воспользуемся алгоритмом ближайших соседей на полученных дексрипторах. Расстояние между дексрипторами будем считать как расстояние Хэмминга.\n",
    "\n",
    "**Вопрос:** Мы используем бинарные дексрипторы. В таком случае, в чем состоит преимущество расстояния Хэмминга в сравнении со стандартным Евклидовым расстоянием?\n",
    "    \n",
    "**Ваш ответ:**\n",
    "\n",
    "Далее, ниже заранее реализованы набор функций, которые помогут вам в выполнении домашнего задания.\n",
    "\n",
    "* `corner_detection` для поиска ключевых точек\n",
    "* `computeBrief` для нахождения BRIEF дексриптора\n",
    "* `briefMatch` матчим точки на основе их BRIEF дескрипторов\n",
    "* `plotMatches` отрисовываем матчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCHWIDTH = 9\n",
    "\n",
    "def briefMatch(desc1, desc2, ratio):\n",
    "    matches = skimage.feature.match_descriptors(desc1, desc2, 'hamming', cross_check=True, max_ratio=ratio)\n",
    "    return matches\n",
    "\n",
    "def plotMatches(im1, im2, matches, locs1, locs2):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "    plt.axis('off')\n",
    "    skimage.feature.plot_matches(ax, im1, im2, locs1, locs2, matches, matches_color='r', only_matches=True)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def makeTestPattern(patchWidth, nbits):\n",
    "    np.random.seed(0)\n",
    "    compareX = patchWidth*patchWidth * np.random.random((nbits,1))\n",
    "    compareX = np.floor(compareX).astype(int)\n",
    "    np.random.seed(1)\n",
    "    compareY = patchWidth*patchWidth * np.random.random((nbits,1))\n",
    "    compareY = np.floor(compareY).astype(int)\n",
    "    return (compareX, compareY)\n",
    "\n",
    "def computePixel(img, idx1, idx2, width, center):\n",
    "    halfWidth = width // 2\n",
    "    col1 = idx1 % width - halfWidth\n",
    "    row1 = idx1 // width - halfWidth\n",
    "    col2 = idx2 % width - halfWidth\n",
    "    row2 = idx2 // width - halfWidth\n",
    "    return 1 if img[int(center[0]+row1)][int(center[1]+col1)] < img[int(center[0]+row2)][int(center[1]+col2)] else 0\n",
    "\n",
    "def computeBrief(img, locs):\n",
    "    patchWidth = 9\n",
    "    nbits = 256\n",
    "    compareX, compareY = makeTestPattern(patchWidth, nbits)\n",
    "    m, n = img.shape\n",
    "\n",
    "    halfWidth = patchWidth//2\n",
    "    \n",
    "    locs = np.array(list(filter(lambda x: halfWidth <= x[0] < m-halfWidth and halfWidth <= x[1] < n-halfWidth, locs)))\n",
    "    desc = np.array([list(map(lambda x: computePixel(img, x[0], x[1], patchWidth, c), zip(compareX, compareY))) for c in locs])\n",
    "    \n",
    "    return desc, locs\n",
    "\n",
    "def corner_detection(img, sigma):\n",
    "    # fast method\n",
    "    result_img = skimage.feature.corner_fast(img, n=PATCHWIDTH, threshold=sigma)\n",
    "    locs = skimage.feature.corner_peaks(result_img, min_distance=1)\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 (10 баллов)\n",
    "Реализуйте функцию `matchPics`, которая принимает два изображения, и находит ключевые точки с соответствиями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchPics(I1, I2, sigma=0.15, ratio=0.7):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        I1, I2: изображения в формате BGR\n",
    "        ratio: параметр для BRIEF\n",
    "        sigma: порог для FAST\n",
    "    \"\"\"\n",
    "\n",
    "    # Ддя начала, делаем оба изображения черно-белыми с помощью opencv\n",
    "    ##### your code here\n",
    "    \n",
    "    # Ищем ключевые точки на первом и втором изображении с помощью corner_detection()\n",
    "    ##### your code here\n",
    "    \n",
    "    # Получаем дексрипторы для найденных ключевых точек для обоих изображений, используя computeBrief()\n",
    "    ##### your code here\n",
    "\n",
    "    # Получаем соответствия (matches) с помощью дескрипторов, используя briefMatch()\n",
    "    ##### your code here\n",
    "    \n",
    "    return matches, locs1, locs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cover = cv2.imread('data/cv_cover.jpg')\n",
    "cv_desk = cv2.imread('data/cv_desk.png')\n",
    "\n",
    "matches, locs1, locs2 = matchPics(cv_cover, cv_desk, sigma=0.15, ratio=0.7)\n",
    "# рисуем матчи\n",
    "plotMatches(cv_cover, cv_desk, matches, locs1, locs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 (10 баллов)\n",
    "Пофайнтюньте параметры sigma и ratio для функции `matchPics`. Опишите ваши наблюдения.\n",
    "\n",
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 (10 баллов)\n",
    "Дополнительно проверьте насколько BRIEF чувствителен к поворотам. Для этого поверните фотографию на x градусов, и посчитатей количество матчей между оригинальной и повернутой фотографией. Увеличивается / уменьшается число матчей? В чем причина? Проанализируйте для x = 0, 10, 20, 30, ..., 350\n",
    "\n",
    "Для поворота фотографии воспользуйтесь `scipy.ndimage.rotate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ищем гомографию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гомография - это операция деформации, которая представляет собой преобразование координат пикселей с одной камеры (изображения, вида, ракурса) к другой камере (изображению, виду, ракурсу). При это делается фундаментальное удтверждение о том, что такое преобразование существует."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (10 баллов)\n",
    "\n",
    "Необходимо найти такую 3x3 матрицу гомографии $\\mathbf{H}$, что выполняется\n",
    "\n",
    "$\\mathbf{x}_{1} \\equiv \\mathbf{H x}_{2}$\n",
    "\n",
    "Точки $\\mathbf{x}_{1}$ и $\\mathbf{x}_{2}$ имеют гомогенные координаты, т.е. $\\left[x_{i}, y_{i}, z_{i}\\right]^{T}$, что соответствует 2D точке $\\left[\\frac{x_{i}}{z_{i}},\\frac{y_{i}}{z_{i}}\n",
    "\\right]^{T}$\n",
    "\n",
    "Так как равенство $\\mathbf{x}_{1} \\equiv \\mathbf{H x}_{2}$ выполняется вне зависимости от масштаба (scale), т.е. соответствует набору равенств $\\mathbf{x}_{1} = \\lambda\\mathbf{H x}_{2}$, то искать $\\mathbf{H}$ методом наименьших квадратов (Ordinary Least Squeares) не  получится, и нужно применить Direct Linear Transform (см. лекцию)\n",
    "\n",
    "т.е. представить $\\mathbf{x}_{1} \\equiv \\mathbf{H x}_{2}$ в виде $Ah=0$, где $h$ - вытянутая в вектор матрица $\\mathbf{H}$ \n",
    "\n",
    "**Вопрос:** Сколько степений свободы (DOF) имеет $\\mathbf{H}$?\n",
    "    \n",
    "**Ваш ответ:**\n",
    "\n",
    "\n",
    "**Вопрос:** Сколько пар точек (матчей) необходимо чтобы вычислить $\\mathbf{H}$? p.s. один матч даёт два уравнения\n",
    "    \n",
    "**Ваш ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeH(x1, x2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x1 (numpy.ndarray): shape [Nx2]. N points from first image\n",
    "        x2 (numpy.ndarray): shape [Nx2]. N points from second image\n",
    "    Returns:\n",
    "        H2to1 (numpy.ndarray): shape [3x3]. Homography matrix\n",
    "    \"\"\"\n",
    "    N = x1.shape[0]\n",
    "    A = np.zeros((2 * N, 3 * 3))\n",
    "    \n",
    "    # Заполните матрицу А используя x1 и x2 (см. лекцию, слайд 270)\n",
    "    ##### your code here\n",
    "\n",
    "    # Решению системы соответствует собственный вектор A^TA с наименьшим собственным числом (см. лекцию)\n",
    "    _, _, eigen_vectors = np.linalg.svd(A)\n",
    "    eigen_vector = eigen_vectors[-1, :]\n",
    "    H2to1 = eigen_vector.reshape(3, 3)\n",
    "    \n",
    "    return H2to1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка\n",
    "\n",
    "x1 = np.array([\n",
    "    [165, 246],\n",
    "    [266, 305],\n",
    "    [337, 228],\n",
    "    [373, 64]\n",
    "])\n",
    "\n",
    "x2 = np.array([\n",
    "    [510, 166],\n",
    "    [364, 382],\n",
    "    [387, 423],\n",
    "    [419, 239],\n",
    "])\n",
    "\n",
    "h2to1_gt = np.array([[-1.38515339e-03, -1.44653089e-03,  9.84208461e-01],\n",
    "                     [-2.21139337e-05, -6.60053015e-04,  1.76988735e-01],\n",
    "                     [-2.32587684e-06, -3.89160630e-06,  2.06042265e-03]])\n",
    "\n",
    "assert np.allclose(computeH(x1, x2), h2to1_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 (10 баллов)\n",
    "Нормализация помогает избежать численной нестабильности и координаты лучше сначала пронормализовать, затем искать гомографию.\n",
    "\n",
    "Делаем следующее:\n",
    "\n",
    "1. Смещаем центроид координат к началу отсчета (0, 0)\n",
    "2. Скалируем точки так, что максимальное расстояние до центра равно $\\sqrt{2}$\n",
    "\n",
    "Такое линейное преобразование можно записать в следующем виде:\n",
    "\n",
    "$$\\begin{array}{l}\n",
    "\\widetilde{\\mathbf{x}}_{1}=\\mathbf{T}_{1} \\mathbf{x}_{1} \\\\\n",
    "\\widetilde{\\mathbf{x}}_{2}=\\mathbf{T}_{2} \\mathbf{x}_{2}\n",
    "\\end{array}$$\n",
    "\n",
    "where $\\widetilde{\\mathbf{x}}_{1}$ и $\\widetilde{\\mathbf{x}}_{2}$􏰂 нормализованные гомогенные координаты, полученные из $\\mathbf{x}_{1}$ и $\\mathbf{x}_{2}$, и матрицы $\\mathbf{T}_{1}$ и $\\mathbf{T}_{2}$ размера 3x3.\n",
    "\n",
    "`computeH` выдает гомографию, которая удовлетворяет:\n",
    "\n",
    "$$\\widetilde{\\mathbf{x}}_{1}=\\mathbf{H} \\widetilde{\\mathbf{x}}_{2}$$\n",
    "\n",
    "Заменяя $\\widetilde{\\mathbf{x}}_{1}$􏰂 и $\\widetilde{\\mathbf{x}}_{2}$ на $\\mathbf{T}_{1}\\mathbf{x}_{1}$ и $\\mathbf{T}_{2}\\mathbf{x}_{2}$, получаем:\n",
    "\n",
    "$$\\begin{array}{l}\n",
    "\\mathbf{T}_{1} \\mathbf{x}_{1}=\\mathbf{H} \\mathbf{T}_{2} \\mathbf{x}_{2} \\\\\n",
    "\\mathbf{x}_{1}=\\mathbf{T}_{1}^{-1} \\mathbf{H} \\mathbf{T}_{2} \\mathbf{x}_{2}\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeH_norm(x1, x2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x1 (numpy.ndarray): shape [Nx2], N точек из первого изображения\n",
    "        x2 (numpy.ndarray): shape [Nx2], N точек из второго изображения\n",
    "    Returns:\n",
    "        H2to1 (numpy.ndarray): shape [3x3]. Homography matrix\n",
    "    \"\"\"\n",
    "    x1_ = x1.astype(float)\n",
    "    x2_ = x2.astype(float)\n",
    "    num_points = x1.shape[0]\n",
    "\n",
    "    # Вычислите два центроида для точек, один для x1, другой для x2\n",
    "    ##### your code here\n",
    "\n",
    "    # Переместите центр координат к центроидам\n",
    "    ##### your code here\n",
    "    # x1_ = ...\n",
    "    # x2_ = ...\n",
    "\n",
    "    # Нормализуйте точки x1 и x2 независимо, так чтобы наибольшая дистанция до сооответствуюшего\n",
    "    # центра координат составляла sqrt(2).\n",
    "    # Для этого достаточно убедиться что ни одна из координат не является по модулю больше 1.\n",
    "    # Нормализуйте каждую из координат (x, y) для каждого из набора точек (x1, x2) по-отдельности\n",
    "    ##### your code here\n",
    "    # x1_[:, 0] = ...\n",
    "    # x1_[:, 1] = ...\n",
    "    # x2_[:, 0] = ...\n",
    "    # x2_[:, 1] = ...\n",
    "\n",
    "    # Выпишем чему равно T1 и T2\n",
    "    T1 = np.dot(np.c_[x1_, np.ones(num_points)].T, np.linalg.pinv(np.c_[x1, np.ones(num_points)].T))\n",
    "    T2 = np.dot(np.c_[x2_, np.ones(num_points)].T, np.linalg.pinv(np.c_[x2, np.ones(num_points)].T))\n",
    "\n",
    "    # Ищем гомографию (см. формулу выше)\n",
    "    H2to1 = computeH(x1_, x2_)\n",
    "    H2to1 = np.linalg.pinv(T1).dot(H2to1).dot(T2)\n",
    "\n",
    "    return H2to1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка\n",
    "\n",
    "x1 = np.array([\n",
    "    [165, 246],\n",
    "    [266, 305],\n",
    "    [337, 228],\n",
    "    [373, 64]\n",
    "])\n",
    "\n",
    "x2 = np.array([\n",
    "    [510, 166],\n",
    "    [364, 382],\n",
    "    [387, 423],\n",
    "    [419, 239],\n",
    "])\n",
    "\n",
    "computeH_norm(x1, x2)\n",
    "\n",
    "h2to1_gt = np.array([[-1.46924418e+00, -1.53434783e+00,  1.04395843e+03],\n",
    "                     [-2.34564407e-02, -7.00123940e-01,  1.87733482e+02],\n",
    "                     [-2.46707768e-03, -4.12786045e-03,  2.18550812e+00]])\n",
    "\n",
    "assert np.allclose(computeH_norm(x1, x2), h2to1_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 RANSAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANSAC - метод поиска параметров модели на основе случайных подвыборок данных, устойчивый к шумам в данных.\n",
    "\n",
    "Это идеально соответствует нашему случаю, мы имеем матчей больше чем необходимо, чтобы найти гомографию. Однако не все матчи правильные (имеем выбросы, шум в данных), что может плохо повлиять на подсчет матрицы гомографии.\n",
    "\n",
    "Ниже представлена уже готовая реализация `computeH_ransac`, внимательно ее изучите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeH_ransac(matches, locs1, locs2, max_iters=1000, inlier_tol=1):\n",
    "    \"\"\"\n",
    "    Найти наилучшую гомографию на основе матчей\n",
    "    \n",
    "    Args:\n",
    "        matches: (numpy.ndarray): shape [Mx2], M пар индексов (i, j) где i-индекс точки из locs1, j-индекс точки из locs2\n",
    "        locs1: (numpy.ndarray): shape [Nx2], N точек из первого изображения\n",
    "        locs2: (numpy.ndarray): shape [Nx2], N точек из второго изображения\n",
    "        max_iters (int): число итераций для RANSAC\n",
    "        inlier_tol (float): порогове значение, при котором точку считаеем inlier (не-выбросом)\n",
    "    Returns:\n",
    "        H2to1 (numpy.ndarray): shape [3x3]. Homography matrix\n",
    "    \"\"\"\n",
    "    locs1 = locs1[matches[:, 0]]\n",
    "    locs2 = locs2[matches[:, 1]]\n",
    "    num_points = locs1.shape[0]\n",
    "    max_inliers = 0\n",
    "    bestH2to1 = np.empty([3, 3], dtype=float)\n",
    "    inliers = np.empty([num_points, 1], dtype=int)\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        points = np.sort(np.random.randint(low=0, high=num_points, size=4))\n",
    "        p1 = locs1[points]\n",
    "        p2 = locs2[points]\n",
    "        try:\n",
    "            # ищем гомографию\n",
    "            H2to1 = computeH_norm(p1, p2)\n",
    "            \n",
    "            # добавляем третью размерность (гомогенный вид)\n",
    "            x1_hom = np.vstack((locs1.T, np.ones((1, num_points))))\n",
    "            x2_hom = np.vstack((locs2.T, np.ones((1, num_points))))\n",
    "            \n",
    "            # деформируем точки x2\n",
    "            new_p1 = H2to1.dot(x2_hom)\n",
    "            \n",
    "            # переходим от гомогенных координат к 2D координатам\n",
    "            new_p1 = new_p1 / new_p1[-1, :]\n",
    "            \n",
    "            # сравниваем деформированные x2 и настоящие точки x1 \n",
    "            error = new_p1 - x1_hom\n",
    "            dist = np.linalg.norm(error, axis=0)\n",
    "            \n",
    "            # если число inliers оказалось больше чем до этого, обновляем лучшего кандидата для матрицы гомографии\n",
    "            consensus = np.where(dist <= inlier_tol)\n",
    "            inliers[consensus] = 1\n",
    "            not_consensus = np.where(dist > inlier_tol)\n",
    "            inliers[not_consensus] = 0\n",
    "            num_inliers = consensus[0].shape[0]\n",
    "            if num_inliers > max_inliers:\n",
    "                max_inliers = num_inliers\n",
    "                bestH2to1 = H2to1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return bestH2to1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Всё вместе (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо деформировать шаблонную картинку в плоскость сцены.\n",
    "\n",
    "Для этого у нас есть три изображения.\n",
    "\n",
    "* Первое (img) - сцена.\n",
    "* Второе (cv_cover) - шаблон обложки книги, которая находится в сцене и мы хотим ее заменить.\n",
    "* Третье (template) - шаблон обложки книги, которую мы вставим в сцену.\n",
    "\n",
    "Заметьте, что мы считаем гомографию от картинки к шаблону.\n",
    "Для того, чтобы сделать наоборот, деформировать шаблон, чтобы выписать его в картинку, необходимо получить матрицу обратную к найденной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compositeH(H2to1, template, img, cv_cover):\n",
    "\n",
    "    # Необходимо изменить размер template, так чтобы он был равен к cv_cover. Воспользуйтесь cv2.resize\n",
    "    ##### your code here\n",
    "\n",
    "    # деформируем template используя матрицу гомографии\n",
    "    template = cv2.warpPerspective(template.swapaxes(0, 1), np.linalg.inv(H2to1), (img.shape[0], img.shape[1])).swapaxes(0, 1)\n",
    "    \n",
    "    # объединяем результат (блендим изображения: template и img)\n",
    "    # p.s. ключевое слово - маска\n",
    "    ##### your code here\n",
    "    \n",
    "    return compositeimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смотрим результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_cover = cv2.imread('data/cv_cover.jpg')\n",
    "cv_desk = cv2.imread('data/cv_desk.png')\n",
    "hp_cover = cv2.imread('data/hp_cover.jpg')\n",
    "\n",
    "matches, locs1, locs2 = matchPics(cv_cover, cv_desk)\n",
    "bestH2to1 = computeH_ransac(matches, locs1, locs2, max_iters=100)\n",
    "composite_img = compositeH(bestH2to1, hp_cover, cv_desk, cv_cover)\n",
    "plt.imshow(cv2.cvtColor(composite_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Должно получиться примерно следующее:\n",
    "![](references/ref.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** Что было бы если мы не изменяли размер template в `compositeH`? Попробуйте запустить без ресайза. Объясните получившийся результат.\n",
    "    \n",
    "**Ваш ответ:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Дополненная реальность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо подставления одного изображения в другое, давайте сделаем это для видео. Всё тоже самое, ведь видео это набор кадров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadVid(path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path: путь к видео\n",
    "    Returns:\n",
    "        frames (numpy.array): shape [TxHxWx3]. Раскадрованное видео\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        i += 1\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            if i == 1:\n",
    "                frames = frame[np.newaxis, ...]\n",
    "            else:\n",
    "                frame = frame[np.newaxis, ...]\n",
    "                frames = np.vstack([frames, frame])\n",
    "                frames = np.squeeze(frames)\n",
    "        else: \n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_cover = cv2.imread('data/cv_cover.jpg')\n",
    "ar_source = loadVid('data/ar_source.mov')\n",
    "book = loadVid('data/book.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Процесс может занять достаточно длительное время\n",
    "\n",
    "# Обрабатываем видео кадр за кадром\n",
    "cap = cv2.VideoWriter('ar.avi', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 15.0, (book.shape[0], book.shape[1]))\n",
    "for frame_num in range(ar_source.shape[0]):\n",
    "    frame_source = ar_source[frame_num]\n",
    "    frame_book = book[frame_num]\n",
    "    matches, locs1, locs2 = matchPics(cv_cover, frame_book)\n",
    "    bestH2to1 = computeH_ransac(matches, locs1, locs2, max_iters=300)\n",
    "    \n",
    "    # обрезаем видео кадр, чтобы не попали черные полосы\n",
    "    frame_source = frame_source[48:-48, 145:495]\n",
    "    \n",
    "    composite_img = compositeH(bestH2to1, frame_source, frame_book, cv_cover)\n",
    "    \n",
    "    cap.write(composite_img)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте такое проделать с вашими данными!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
