{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашние задания являются полностью опциональными, оценки никуда не идут.\n",
    "\n",
    "### Дедлайн: 21.06.20 (вс) 21:00 мск\n",
    "\n",
    "### Формат сдачи\n",
    "\n",
    "__Вариант 1__: этот ipynb файл с кодом\n",
    "\n",
    "дополнительно добавьте:\n",
    "* \"checkpoint\" файл из `torch.save(model.state_dict(), ...)` который содержит веса модели для задачи 1, 3 и поможет удостовериться в точности на валидации\n",
    "* имеется возможность перезапустить весь ipynb файл, чтобы убедиться в финальном результате, например в 1й и 3й задаче (можете сделать конструкцию if else, н: если файл с весами присутствует, тогда показываем точность, иначе запускаем training рутину и выводим в конце точность)\n",
    "\n",
    "__Вариант 2__:\n",
    "сдаёте в виде набора .py скриптов (н. train.py, test.py, ...) на каждое задание с инструкцией как запустить и убедиться в полученных вами результатах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1 - Train your own model (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вы построете сверточную нейросеть (CNN) для решения Tiny ImageNet классификации. Постарайтесь добиться максимальной точности на валидации.\n",
    "\n",
    "### Оценивание\n",
    "\n",
    "* За преодоление каждого порога даётся 1 балл\n",
    "  * 25.0%\n",
    "  * 30.0%\n",
    "  * 32.5%\n",
    "  * 35.0%\n",
    "  * 37.5%\n",
    "  * 40.0%\n",
    "    \n",
    "### Ограничения\n",
    "\n",
    "* __Нельзя использовать предобученные нейросети.__ Сами архитектуры использовать можно.\n",
    "\n",
    "### Советы\n",
    "\n",
    "* Одно изменение в один момент времени\n",
    "* Используйте GPU, постарайтесь написать device-agnostic код, чтобы нигде не присутствовало `.cuda()`, а было `.to(device)`\n",
    "* Логируйте промежуточный результаты, например в TensorBoard\n",
    "* С чем можно поиграться: optimizer, lr scheduler, архитектура, инициализации, loss, регуляризации (dropout, cutmix, weight decay, аугментации и тд), и кучу всего разного\n",
    "* Про \"фишечки\", которые можно внедрить для улучшения качества, можно посмотреть здесь https://arxiv.org/abs/1812.01187\n",
    "* Постарайтесь по максимуму переиспользовать написанный код, то есть реализовать в виде набора функций например тренировочную рутину и ее использовать в задаче 1, 2, 4\n",
    "* Как обычно: читабельный, понятный код приветствуется\n",
    "\n",
    "### Какую архитектуру выбрать для обучения?\n",
    "* пишем сами\n",
    "* берём готовую архитектуру (например отсюда https://github.com/rwightman/pytorch-image-models (очень классный ресурс с модными архитектурами) или отсюда https://pytorch.org/docs/stable/torchvision/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiny_imagenet\n",
    "tiny_imagenet.download(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренировочные и валидационные данные лежат в `tiny-imagenet-200/train` и `tiny-imagenet-200/val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда закончите обучение, сделайте отдельно инференс на валидации и выведите ниже результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = comput_val_acc(...)\n",
    "print(\"Validation accuracy: %.2f%%\" % (val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отчет\n",
    "\n",
    "Кратако укажите, что вы попробывали, что получилось и дало прирост, а что нет\n",
    "\n",
    "Сколько параметров у модели?\n",
    "\n",
    "Как быстро она предсказывает класс для 1й картинки?\n",
    "\n",
    "Oпцианально: выведите top-1, top-5 точность вашей модели\n",
    "\n",
    "Опцианально: выведите картинки, на которых ваша модель сильнее всего ошибается (вероятность класса, соответствующая таргету, минимальная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2 - Transfer Learning (1 балл)\n",
    "\n",
    "Выберите любую предобученную модель. Сделайте transfer learning для датасета из задачи 1. Постарайтесь по-максимуму воспользоваться кодом из задачи 1, чтобы не дублировать его. Выведите точность на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 3 - Grouped Convolutions (2 балла)\n",
    "\n",
    "Задача на понимание групповых сверток.\n",
    "\n",
    "Стандартный вариант указать параметр __groups__  у `nn.Conv2d` и вызвать стандартный forward.\n",
    "\n",
    "Попробуйте написать `forward` сами, воспользовавшись `torch.nn.functional.conv2d()` с одним ограничением, что параметр __groups__ в `torch.nn.functional.conv2d()` передавать нельзя.\n",
    "\n",
    "Для решения советую циклом пройтись по `range(out_channels)` возможно с ненулевым шагом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def custom_forward(conv, x):\n",
    "    # put your code here\n",
    "    return result\n",
    "\n",
    "conv = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3, groups=2, padding=1)\n",
    "x = torch.rand(1, 8, 16, 16)\n",
    "assert torch.allclose(conv(x), custom_forward(conv, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 4 - Self-supervised learning (много баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы дошли до задачи 4 и у вас еще много сил, энергии и времени, то вот вам настоящий challenge:\n",
    "\n",
    "Прочитайте статью про FixMatch https://arxiv.org/abs/2001.07685\n",
    "\n",
    "Вам предлагается в каком-либо виде воспользоваться предлагаемым в статье новым loss-ом применимо к задаче 1. А именно: в статье предлагается вариант того, как эффективно воспользоваться неразмеченными данными для улучшения качества модели.\n",
    "Если у вас написан хороший код для задачи 1, то не должно вызвать больших трудностей добавить упомянутый подход.\n",
    "Смотреть / использовать готовые какие-то реализации разрешается, главное вы должны понимать код, которым воспользовались.\n",
    "\n",
    "Пара советов:\n",
    "* скорей всего в одной из лекций мы покроем как писать свой вариант кастомный класс для загрузки данных, но вы можете сейчас попробовать погуглить (pytorch custom dataset) - он вам скорей всего понадобится, чтобы грузить одновременно размеченные и неразмеченные данные в 1 батче\n",
    "* неразмеченные данные можно взять из любого другого датасета, например cifar-100 либо же для начала можно просто имеющиеся train данные поделить на две части и забыть про существование таргетов на одной из частей\n",
    "* воспользуйтесь той же самой моделью и теми же самыми параметрами оптимизатора и т.д какие вы выбрали в 1й задаче\n",
    "* сильные и слабые аугментации (см. статью) можете сделать внутри вашего кастомного класса с датасетом (т.е. агументировать данные до отправки на gpu) либо делать их уже после загрузки батча из dataloader (желательно на гпу). Во втором варианте советую воспользоваться https://kornia.readthedocs.io/en/latest/augmentation.html\n",
    "* аугментации можете для дз сделать любые свои в качестве слабых и сильных, но на будущее старайтесь реимплемнтировать разные походы из статей как можно более похожим образом для начала, если еще нет интуиции как поменять что-то под вашу задачу, чтобы в случае если вы встраивате метод в какой-то пайплайн и у вас в итоге плохое качество, знать что в этом месте например проблемы нет, значит надо искать в другом месте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
