{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch MNIST Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных MNIST представляет собой большую базу рукописных цифр, которая обычно используется для обучения различных систем обработки изображений. База данных также широко используется для обучения и тестирования в области машинного обучения.\n",
    "\n",
    "Он состоит из 60000 изображений для трейна и 10000 тестовых изображений.\n",
    "\n",
    "![MNIST Examples](mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если гпу у вас несколько укажите номер гпу, которую хотите использовать\n",
    "# номер свободной можно посмотреть с помощью nvidia-smi в терминале\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the MNIST Train and Test set \n",
    "Используя torch.utils.data DataLoader, мы перемешиваем данные и устанавливаем размера батча равный 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "test = MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "dataloader_args = dict(shuffle=True, batch_size=256,num_workers=4, pin_memory=True) if cuda \\\n",
    "                        else dict(shuffle=True, batch_size=64)\n",
    "train_loader = dataloader.DataLoader(train, **dataloader_args) \n",
    "test_loader = dataloader.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute basic data statistics\n",
    "Всегда важно посчитать размер данных и основные статистики min/max и mean/variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.train_data\n",
    "train_data = train.transform(train_data.numpy())\n",
    "\n",
    "print('[Train]')\n",
    "print(' - Numpy Shape:', train.train_data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', train.train_data.size())\n",
    "print(' - min:', torch.min(train_data))\n",
    "print(' - max:', torch.max(train_data))\n",
    "print(' - mean:', torch.mean(train_data))\n",
    "print(' - std:', torch.std(train_data))\n",
    "print(' - var:', torch.var(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a few training samples\n",
    "Используем matplotlib.pyplot для визуализации данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a training instance with matplotlib\n",
    "plt.imshow(train.train_data.cpu().numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train.train_data.cpu().numpy()[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Neural Network Model \n",
    "Определим нашу модель используя класс torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE MODEL DEFINITION\n",
    "class Simple_MLP(nn.Module):\n",
    "    def __init__(self, size_list):\n",
    "        super(Simple_MLP, self).__init__()\n",
    "        layers = []\n",
    "        self.size_list = size_list\n",
    "        for i in range(len(size_list) - 2):\n",
    "            layers.append(nn.Linear(size_list[i],size_list[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.size_list[0]) # Flatten the input\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model and define the Loss and Optimizer\n",
    "\n",
    "Создаем инстанс модели Simple_MLP передавая ей размеры слоев в качестве праметров. Входной слой содержит 28*28 = 784 нейронов. Мы определяем скрытый слой размера 256, и выходной слой размера 10, соответствующий  вероятностям 10 цифр (0-9).\n",
    "\n",
    "Так как это задача классификации, будем использовать Cross Entropy Loss. Мы определяем лосс (критерий) как torch.nn.CrossEntropyLoss.\n",
    "\n",
    "Для обучения сети воспользуемся torch.optim.SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_MLP([784, 256, 10])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function that will train the network for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   \n",
    "        data = data.to(device)\n",
    "        target = target.long().to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    running_loss /= len(train_loader)\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function that will evaluate our network's performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):   \n",
    "            data = data.to(device)\n",
    "            target = target.long().to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Testing Loss: ', running_loss)\n",
    "        print('Testing Accuracy: ', acc, '%')\n",
    "        return running_loss, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model for N epochs\n",
    "Мы тренируем и тестируем сеть в цикле, отслеживая лоссы и точность (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "    Train_loss.append(train_loss)\n",
    "    Test_loss.append(test_loss)\n",
    "    Test_acc.append(test_acc)\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(Train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Test Loss')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(Test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.plot(Test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
