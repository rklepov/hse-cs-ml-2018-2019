{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow: классификация изображений MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции инициализаии переменных и создания слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    \"\"\" Преобразование тензора в вектор \"\"\"\n",
    "    size = 1\n",
    "    for dimension in x.shape[1:]:\n",
    "        size *= dimension.value\n",
    "    return tf.reshape(x, [-1, size])\n",
    "\n",
    "def fc(x, size):\n",
    "    \"\"\" Полносвязный слой \"\"\"\n",
    "    in_size = x.shape[-1].value  # получаем размерность входных данных\n",
    "    # тензор весов нейронов\n",
    "    w_shape = [in_size, size]\n",
    "    w = tf.get_variable(name='w', initializer=tf.truncated_normal(shape=w_shape))\n",
    "    # тензор свободных членов нейронов\n",
    "    b_shape = [size]\n",
    "    b = tf.get_variable(name='b', initializer=tf.truncated_normal(shape=b_shape))\n",
    "    return tf.matmul(x, w) + b    \n",
    "\n",
    "def conv2d(x, ksize, filters):\n",
    "    \"\"\" Реализация операции 2D-свертки \"\"\"\n",
    "    x_channels = x.shape[-1].value  # число каналов во входном тензоре\n",
    "    # тензор сверточных фильтров\n",
    "    w_shape = [ksize, ksize, x_channels, filters]\n",
    "    w = tf.get_variable(name='w', initializer=tf.truncated_normal(shape=w_shape))\n",
    "    # свободный член\n",
    "    b_shape = [filters]\n",
    "    b = tf.get_variable(name='b', initializer=tf.truncated_normal(shape=b_shape))\n",
    "    return tf.nn.conv2d(x, filter=w, strides=[1, 1, 1, 1], padding='SAME') + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задаем архитектуру сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "optimzer = tf.train.AdamOptimizer(learning_rate=3e-4)\n",
    "\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 28, 28, 1]) # входные изображения размера 28x28\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, 10])  # one-hot encoding на 10 классов\n",
    "\n",
    "    with tf.variable_scope('conv_1'):\n",
    "        conv_1 = conv2d(X, ksize=5, filters=8)\n",
    "        conv_1 = tf.nn.relu(conv_1)\n",
    "        conv_1 = tf.nn.max_pool(conv_1,\n",
    "                                ksize=[1, 2, 2, 1], \n",
    "                                strides=[1, 2, 2, 1],\n",
    "                                padding='SAME')\n",
    "        \n",
    "    with tf.variable_scope('conv_2'):\n",
    "        conv_2 = conv2d(conv_1, ksize=5, filters=16)\n",
    "        conv_2 = tf.nn.relu(conv_2)\n",
    "        conv_2 = tf.nn.max_pool(conv_2,\n",
    "                                ksize=[1, 2, 2, 1], \n",
    "                                strides=[1, 2, 2, 1],\n",
    "                                padding='SAME')\n",
    "    \n",
    "    with tf.variable_scope('fc1'):\n",
    "        fc1 = flatten(conv_2)\n",
    "        fc1 = fc(fc1, size=10)\n",
    "\n",
    "    loss = tf.losses.softmax_cross_entropy(Y, fc1)\n",
    "    train_step = optimzer.minimize(loss)\n",
    "    \n",
    "    prediction = tf.nn.softmax(fc1, name='prediction')\n",
    "    # TODO: добавить подсчет доли правильных ответов (accuracy)\n",
    "    \n",
    "    summary_train = tf.summary.merge([\n",
    "        tf.summary.scalar('train/loss', loss),])\n",
    "\n",
    "    summary_test = tf.summary.merge([\n",
    "        tf.summary.scalar('test/loss', loss),])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запускаем процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./log/002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./log/002', sess.graph)\n",
    "    \n",
    "    for i in range(500):\n",
    "        # загружаем данные для шага обучения\n",
    "        train_images, train_labels = mnist.train.next_batch(50)\n",
    "        train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "        # вычисляем градиенты и обновляем параметры модели\n",
    "        (_,\n",
    "         train_loss,\n",
    "         train_summary) = sess.run([train_step,\n",
    "                                    loss,\n",
    "                                    summary_train],\n",
    "                                   feed_dict={X: train_images,\n",
    "                                              Y: train_labels})\n",
    "        # логируем данные для вывода на tensorboard\n",
    "        writer.add_summary(train_summary, global_step=i)  \n",
    "        \n",
    "        if i % 100 == 0:  # оцениваем качество модели на тесте\n",
    "            test_images = mnist.test.images.reshape(-1, 28, 28, 1)\n",
    "            (test_loss,\n",
    "             test_summary) = sess.run([loss,\n",
    "                                       summary_test],\n",
    "                                      feed_dict={X: test_images,\n",
    "                                                 Y: mnist.test.labels})\n",
    "            # логируем данные для вывода на tensorboard\n",
    "            writer.add_summary(test_summary, global_step=i)\n",
    "            print('[%04d] train_loss=%g test_loss=%g' % (i, train_loss, test_loss))\n",
    "            \n",
    "        writer.flush()\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация в tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запускаем интерфейс визуализации\n",
    "!tensorboard --port 8800 --host 0.0.0.0 --logdir ./log/002"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
