{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация логистической регрессии в TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерируем данные для задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2\n",
    "NUM_SAMPLES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = NUM_SAMPLES,\n",
    "                           n_features = NUM_FEATURES,\n",
    "                           n_informative = NUM_FEATURES,\n",
    "                           n_redundant = 0,\n",
    "                           n_classes = 2,\n",
    "                           n_clusters_per_class = 1,\n",
    "                           class_sep = 0.75,\n",
    "                           random_state = 54312)\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "ones = np.where(y == 1)   # индексы объектов класса '1'\n",
    "zeros = np.where(y == 0)  # индексы объектов класса '0'\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(X[ones, 0], X[ones, 1], 'ob',\n",
    "         X[zeros, 0], X[zeros, 1], 'or');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательная функция для создания операций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def py_func_with_grad(func, inp, Tout, grad, name = None, stateful = False, graph = None):\n",
    "    \n",
    "    name_prefix = ''.join(np.random.choice(list(string.ascii_letters), size = 10))\n",
    "    \n",
    "    name = '%s_%s' % (name_prefix, name or '')\n",
    "    grad_func_name = '%s_grad' % name\n",
    "\n",
    "    tf.RegisterGradient(grad_func_name)(grad)\n",
    "\n",
    "    g = graph or tf.get_default_graph()\n",
    "    with g.gradient_override_map({'PyFunc': grad_func_name, \n",
    "                                  'PyFuncStateless': grad_func_name}):\n",
    "        with tf.name_scope(name, 'PyFuncOp', inp):\n",
    "            return tf.py_func(func, inp, Tout, stateful = stateful, name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация линейной опреаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_op_forward(X, W):\n",
    "    ''' Реализация линейной операции '''\n",
    "    return np.dot(X, W.T)  # аргументы являются numpy-массивами\n",
    "\n",
    "def linear_op_backward(op, grads):\n",
    "    ''' Реализация вычисления градиента линейной операции '''\n",
    "    X = op.inputs[0]  # тензор входных данных\n",
    "    W = op.inputs[1]  # тензор параметров модели\n",
    "    dX = tf.multiply(grads, W)\n",
    "    dW = tf.reduce_sum(tf.multiply(X, grads),\n",
    "                       axis = 0,\n",
    "                       keep_dims = True)\n",
    "    return dX, dW\n",
    "\n",
    "def sigmoid_op_forward(X):\n",
    "    # TODO: реализовать операцию sigmoid\n",
    "    return np.zeros_like(X)\n",
    "\n",
    "def sigmoid_op_backward(op, grads):\n",
    "    # TODO: реализовать вычисление градиента для sigmoid\n",
    "    return tf.zeros([1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание графа вычислений и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = NUM_SAMPLES // 10\n",
    "\n",
    "weights = None  # в этой переменной мы сохраним результат обучения модели\n",
    "learning_curve = []  # значения ошибки на каждой итерации обучения\n",
    "\n",
    "with tf.Session(graph = tf.Graph()) as sess:  # инициализируем сессию вычислений\n",
    "    \n",
    "    # создаем placeholdr'ы, через них мы будем\n",
    "    # передавать внешние данные в граф вычислений\n",
    "    plh_X = tf.placeholder(dtype = tf.float32, shape = [None, NUM_FEATURES])\n",
    "    plh_labels = tf.placeholder(dtype = tf.float32, shape = [None, 1])\n",
    "\n",
    "    # создаем переменную для хранения весов модели\n",
    "    # эти веса будут изменяться в процессе обучения\n",
    "    var_W = tf.Variable(tf.random_uniform(shape = [1, NUM_FEATURES],\n",
    "                                          dtype = tf.float32,\n",
    "                                          seed = 54321))\n",
    "    \n",
    "    # создаем переменную для результата предсказания модели\n",
    "    var_Pred = py_func_with_grad(linear_op_forward,         # функция предсказания модели \n",
    "                                 [plh_X, var_W],            # аргументы функции\n",
    "                                 [tf.float32],              # тип выходных значений\n",
    "                                 name = 'linear_op',        # имя операции \n",
    "                                 grad = linear_op_backward, # функция для вычисления градиента\n",
    "                                 graph = sess.graph)        # объект графа вчислений\n",
    "    \n",
    "    # создаем переменную для результата операции sigmoid\n",
    "    var_Sigmoid = py_func_with_grad(sigmoid_op_forward,\n",
    "                                    [var_Pred],\n",
    "                                    [tf.float32],\n",
    "                                    name = 'sigmoid_op',\n",
    "                                    grad = sigmoid_op_backward,\n",
    "                                    graph = sess.graph)\n",
    "    \n",
    "    # кроссэнтропийная функция потерь для бмнарной классификации\n",
    "    cost = tf.losses.sigmoid_cross_entropy(plh_labels, var_Sigmoid)\n",
    "    \n",
    "    # инициализируем оптимизатор и указываем скорость обучения\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.9).minimize(cost)\n",
    "\n",
    "    # инициализируем placeholder'ы и переменные\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    indices = np.arange(len(X))  # массив индексов объектов\n",
    "    \n",
    "    # выполняем итерации по 10-ти эпохам\n",
    "    for epoch in range(10):\n",
    "        \n",
    "        # вначале каждой эпохи перемешиваем индексы\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # внутри каждой эпохи данные разбиваются на батчи\n",
    "        for batch in range(len(X) // BATCH_SIZE):\n",
    "            \n",
    "            # выбираем индексы очередного батча\n",
    "            batch_indices = indices[batch * BATCH_SIZE:(batch + 1) * BATCH_SIZE]\n",
    "\n",
    "            # выполняем шаг обучения: вычисляем ошибку и обновляем веса\n",
    "            loss, _ = sess.run([cost, optimizer],  # указываем, какие операции необходимо выполнить\n",
    "                               feed_dict = {plh_X: X[batch_indices],  # передаем входные данные для вычисления\n",
    "                                            plh_labels: y[batch_indices]})\n",
    "        \n",
    "            # сохраняем занчения ошибки для построения кривой обучения\n",
    "            learning_curve.append(loss)\n",
    "            \n",
    "            # выводим текущее значение ошибки для каждого 10го шага\n",
    "            steps = len(learning_curve) - 1\n",
    "            if steps % 10 == 0:\n",
    "                print('[%03d] loss=%.3f weights=%s' % (steps, loss, var_W.eval()))\n",
    "    \n",
    "    # сохраняем обученные веса\n",
    "    weights = var_W.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем кривую обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Learning curve')\n",
    "plt.plot(learning_curve);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем разделяющую гиперплоскость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = - X[:, 0] * weights[0, 0] / weights[0, 1]\n",
    "\n",
    "order = np.argsort(X[:, 0])\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(X[ones, 0], X[ones, 1], 'ob',\n",
    "         X[zeros, 0], X[zeros, 1], 'or',\n",
    "         X[order, 0], y_pred[order], '-g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
