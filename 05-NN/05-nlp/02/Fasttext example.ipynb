{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-27 07:57:50--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2019-04-27 07:57:51--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucc63635798d6f4b8d4e3ffeca4b.dl.dropboxusercontent.com/cd/0/inline/AfyYLPEpTpIxEXM4MwohrvyXf6yP2T9Ss0mXKovPwUPQTIG9biz1aOSu54l7BNc9AbGetX3iE0TuoOiMLvLiWk0_UZgPv-PnYkA2xZhBGRp3cAIngdy2ng6N0eCX9fcx2oM/file# [following]\n",
      "--2019-04-27 07:57:51--  https://ucc63635798d6f4b8d4e3ffeca4b.dl.dropboxusercontent.com/cd/0/inline/AfyYLPEpTpIxEXM4MwohrvyXf6yP2T9Ss0mXKovPwUPQTIG9biz1aOSu54l7BNc9AbGetX3iE0TuoOiMLvLiWk0_UZgPv-PnYkA2xZhBGRp3cAIngdy2ng6N0eCX9fcx2oM/file\n",
      "Resolving ucc63635798d6f4b8d4e3ffeca4b.dl.dropboxusercontent.com (ucc63635798d6f4b8d4e3ffeca4b.dl.dropboxusercontent.com)... 162.125.70.6\n",
      "Connecting to ucc63635798d6f4b8d4e3ffeca4b.dl.dropboxusercontent.com (ucc63635798d6f4b8d4e3ffeca4b.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: 'positive.csv?dl=0'\n",
      "\n",
      "positive.csv?dl=0   100%[===================>]  25.02M  2.96MB/s    in 8.5s    \n",
      "\n",
      "2019-04-27 07:58:00 (2.96 MB/s) - 'positive.csv?dl=0' saved [26233379/26233379]\n",
      "\n",
      "--2019-04-27 07:58:00--  http://positive.csv/\n",
      "Resolving positive.csv (positive.csv)... failed: nodename nor servname provided, or not known.\n",
      "wget: unable to resolve host address 'positive.csv'\n",
      "FINISHED --2019-04-27 07:58:00--\n",
      "Total wall clock time: 10s\n",
      "Downloaded: 1 files, 25M in 8.5s (2.96 MB/s)\n",
      "--2019-04-27 07:58:00--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2019-04-27 07:58:01--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc5ec05f6459d4a0395320ae52b3.dl.dropboxusercontent.com/cd/0/inline/AfwnDgpyr4keg___5TfH_sT0j4T3wgdvf_qNWyWNx74BXD35yV-Tv51JNtZSgX7n6rN5fgt8H2PWBkp-i0hHaC1_jrgdizP3KJSZiQkOMZYzXjXjGEnYhCbYnnnv5gOjCio/file# [following]\n",
      "--2019-04-27 07:58:01--  https://uc5ec05f6459d4a0395320ae52b3.dl.dropboxusercontent.com/cd/0/inline/AfwnDgpyr4keg___5TfH_sT0j4T3wgdvf_qNWyWNx74BXD35yV-Tv51JNtZSgX7n6rN5fgt8H2PWBkp-i0hHaC1_jrgdizP3KJSZiQkOMZYzXjXjGEnYhCbYnnnv5gOjCio/file\n",
      "Resolving uc5ec05f6459d4a0395320ae52b3.dl.dropboxusercontent.com (uc5ec05f6459d4a0395320ae52b3.dl.dropboxusercontent.com)... 162.125.70.6\n",
      "Connecting to uc5ec05f6459d4a0395320ae52b3.dl.dropboxusercontent.com (uc5ec05f6459d4a0395320ae52b3.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: 'negative.csv?dl=0'\n",
      "\n",
      "negative.csv?dl=0   100%[===================>]  23.32M  2.94MB/s    in 7.9s    \n",
      "\n",
      "2019-04-27 07:58:10 (2.95 MB/s) - 'negative.csv?dl=0' saved [24450101/24450101]\n",
      "\n",
      "--2019-04-27 07:58:10--  http://negative.csv/\n",
      "Resolving negative.csv (negative.csv)... failed: nodename nor servname provided, or not known.\n",
      "wget: unable to resolve host address 'negative.csv'\n",
      "FINISHED --2019-04-27 07:58:10--\n",
      "Total wall clock time: 9.3s\n",
      "Downloaded: 1 files, 23M in 7.9s (2.95 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0' positive.csv\n",
    "!wget 'https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0' negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pd.read_csv('positive.csv?dl=0',header=None,encoding='utf-8',delimiter=';')\n",
    "negative = pd.read_csv('negative.csv?dl=0',header=None,encoding='utf-8',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=positive[[positive.columns[3]]]\n",
    "negative=negative[[negative.columns[3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive['target']=1\n",
    "negative['target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive.columns=['text','target']\n",
    "negative.columns=['text','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  @first_timee хоть я и школота, но поверь, у на...       1\n",
       "1  Да, все-таки он немного похож на него. Но мой ...       1\n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...       1\n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...       1\n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = pd.concat([positive,negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(full_set['text'],full_set.target.values,test_size=0.2,shuffle=True,random_state=2121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(TfidfVectorizer(ngram_range=(1,2)),MultinomialNB())\n",
    "clf.fit(x_train,y_train)\n",
    "preds = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7739546366301496"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь опробуем на этих же данных простейшую сеть с предобученными ембедингами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-27 08:01:17--  http://files.deeppavlov.ai/embeddings/ft_native_300_ru_twitter_nltk_word_tokenize.vec\n",
      "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
      "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2767469831 (2.6G) [application/octet-stream]\n",
      "Saving to: 'ft_native_300_ru_twitter_nltk_word_tokenize.vec'\n",
      "\n",
      "ft_native_300_ru_tw 100%[===================>]   2.58G  2.94MB/s    in 15m 14s \n",
      "\n",
      "2019-04-27 08:16:32 (2.89 MB/s) - 'ft_native_300_ru_twitter_nltk_word_tokenize.vec' saved [2767469831/2767469831]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.deeppavlov.ai/embeddings/ft_native_300_ru_twitter_nltk_word_tokenize.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i350114/Documents/python_env/pyth3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9889c78acb494bac8de4098784fccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('ft_native_300_ru_twitter_nltk_word_tokenize.vec')\n",
    "embedding_values = {}\n",
    "for line in tqdm_notebook(f):\n",
    "    value = line.replace('\\n','').split(' ')\n",
    "    word = value[0]\n",
    "    coef = np.array(value[1:-1],dtype = 'float32')\n",
    "    embedding_values[word]=coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 291376 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(full_set['text'])\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6de60b636754b139f7a7bf768f0952a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=291376), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1, 100),dtype=np.float32)\n",
    "sum_finding=0\n",
    "for word, i in tqdm_notebook(word_index.items()):\n",
    "    try:\n",
    "        embedding_vector = embedding_values[word]\n",
    "        sum_finding=sum_finding+1\n",
    "    except:\n",
    "        embedding_vector = embedding_values[\"unknown\"]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нашли векторов -  147597\n"
     ]
    }
   ],
   "source": [
    "print('Нашли векторов - ',sum_finding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готовим модель...\n",
      "Обучаем...\n",
      "Train on 181467 samples, validate on 45367 samples\n",
      "Epoch 1/25\n",
      "181467/181467 [==============================] - 33s 182us/sample - loss: 0.6468 - accuracy: 0.6087 - val_loss: 0.6247 - val_accuracy: 0.6318\n",
      "Epoch 2/25\n",
      "181467/181467 [==============================] - 32s 176us/sample - loss: 0.6230 - accuracy: 0.6310 - val_loss: 0.6149 - val_accuracy: 0.6389\n",
      "Epoch 3/25\n",
      "181467/181467 [==============================] - 32s 174us/sample - loss: 0.6153 - accuracy: 0.6380 - val_loss: 0.6115 - val_accuracy: 0.6418\n",
      "Epoch 4/25\n",
      "181467/181467 [==============================] - 31s 171us/sample - loss: 0.6108 - accuracy: 0.6448 - val_loss: 0.6122 - val_accuracy: 0.6392\n",
      "Epoch 5/25\n",
      "181467/181467 [==============================] - 31s 171us/sample - loss: 0.6066 - accuracy: 0.6482 - val_loss: 0.6071 - val_accuracy: 0.6448\n",
      "Epoch 6/25\n",
      "181467/181467 [==============================] - 31s 169us/sample - loss: 0.6038 - accuracy: 0.6514 - val_loss: 0.5986 - val_accuracy: 0.6593\n",
      "Epoch 7/25\n",
      "181467/181467 [==============================] - 33s 182us/sample - loss: 0.6003 - accuracy: 0.6561 - val_loss: 0.5943 - val_accuracy: 0.6630\n",
      "Epoch 8/25\n",
      "181467/181467 [==============================] - 33s 184us/sample - loss: 0.5959 - accuracy: 0.6601 - val_loss: 0.5908 - val_accuracy: 0.6666\n",
      "Epoch 9/25\n",
      "181467/181467 [==============================] - 33s 182us/sample - loss: 0.5933 - accuracy: 0.6632 - val_loss: 0.5892 - val_accuracy: 0.6695\n",
      "Epoch 10/25\n",
      "181467/181467 [==============================] - 33s 180us/sample - loss: 0.5899 - accuracy: 0.6661 - val_loss: 0.5841 - val_accuracy: 0.6713\n",
      "Epoch 11/25\n",
      "180992/181467 [============================>.] - ETA: 0s - loss: 0.5857 - accuracy: 0.6711"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0f95d5fbf457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Обучаем...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m model.fit(X_train, y_train, batch_size=batch_size, epochs=25,\n\u001b[0;32m---> 39\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     40\u001b[0m score, acc = model.evaluate(X_test, y_test,\n\u001b[1;32m     41\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    399\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3214\u001b[0m               'You must feed a value for placeholder %s' % (tensor,))\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3216\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3217\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3218\u001b[0m         \u001b[0;31m# Temporary workaround due to `convert_to_tensor` not casting floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1048\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1049\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1050\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    302\u001b[0m                                          as_ref=False):\n\u001b[1;32m    303\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    243\u001b[0m   \"\"\"\n\u001b[1;32m    244\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 245\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_env/pyth3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337) \n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 40  \n",
    "batch_size = 256 \n",
    "\n",
    "print('Готовим модель...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    len(word_index)+1,\n",
    "    100,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=maxlen,\n",
    "    trainable=False\n",
    "))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(GRU(32)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-3,clipnorm=5,clipvalue=5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
    "\n",
    "print('Обучаем...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=25,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Тест score:', score)\n",
    "print('Тест accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
