{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глава 2. Сверточные нейронные сети\n",
    "# Часть 2. Приложения компьютерного зрения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зачем изучать компьютерное зрение?\n",
    "Наиболее очевидный ответ заключается в том, что существует быстроразвивающие полезные приложения, полученных из этой области исследований. Вот лишь несколько из них:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Распознавание лиц:** Snapchat и Facebook используют алгоритмы распознавания лиц, чтобы применять фильтры и распознавать вас на фотографиях.\n",
    "\n",
    "\n",
    "* **Поиск изображений:** Google Images использует контентные запросы для поиска релевантных изображений. Алгоритмы анализируют содержимое в изображении запроса и возвращают результаты на основе наиболее подходящего содержимого.\n",
    "\n",
    "\n",
    "* **Игры и управление:** Отличным коммерческим продуктом в играх, использующим стереозрение, является Microsoft Kinect.\n",
    "\n",
    "\n",
    "* **Наблюдение:** Камеры наблюдения широко распространены в общественных местах и используются для выявления подозрительных действий.\n",
    "\n",
    "\n",
    "* **Биометрия:** отпечатки пальцев, радужная оболочка лица и идентификация лица остаются некоторыми распространенными методами биометрической идентификации.\n",
    "\n",
    "\n",
    "* **Беспилотные автомобили:** Зрение остается основным источником информации для обнаружения дорожных знаков и огней и других визуальных функций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последние разработки в области нейронных сетей и подходов к глубокому обучению значительно повысили возможности современных систем визуального распознавания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Классификация изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача классификации изображений звучит следующим образом: учитывая набор изображений, каждое из которых помечены одной категорией, нас просят предсказать эти категории для нового набора тестовых изображений и измерить точность прогноза.\n",
    "\n",
    "Существует множество проблем, связанных с этой задачей, в том числе изменение точки обзора, изменение масштаба, внутриклассовая вариация, деформация изображения, доступность объекта на изображении (окклюзия), условия освещения и фоновый беспорядок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Задача Cats vs Dogs (Keras)\n",
    "* Домашняя задача\n",
    "* Transfer Learning\n",
    "* Задача Flowers (fastai)\n",
    "* Задача Planets (fastai)\n",
    "* Домашняя задача (Plants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Литература\n",
    "* ImageNet http://www.image-net.org/\n",
    "* AlexNet (2012) http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf\n",
    "* ZFNet (2013) https://arxiv.org/pdf/1311.2901.pdf\n",
    "* GoogleNet (2014) https://arxiv.org/pdf/1409.4842.pdf\n",
    "* VGG (2014) https://arxiv.org/pdf/1409.1556.pdf\n",
    "* ResNet (2015) https://arxiv.org/pdf/1512.03385.pdf\n",
    "* DenseNet (2016) https://arxiv.org/pdf/1608.06993.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Детектирование объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача детектирования объектов на изображении обычно включает вывод ограничивающих рамок (bounding boxes) и меток (labels) для отдельных объектов. Это отличается от задачи классификации / локализации тем, что применяет классификацию и локализацию ко многим объектам, а не только к одному главному объекту на изображении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, при обнаружении автомобилей вы должны обнаружить все автомобили на заданном изображении с помощью их ограничительных рамок (bounding boxes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы используем метод скользящего окна, например, как мы классифицируем и локализуем объект на изображении, нам нужно применить CNN ко многим различным сегментам (кропам) изображения. Поскольку CNN классифицирует каждую ситуацию как объект или фон, мы должны применить CNN к огромному количеству местоположений и масштабов, что очень дорого в вычислительном отношении!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какое есть решение?** По сути, мы можем превратить обнаружение объектов в задачу классификации изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первой моделью, с которой все началось, была R-CNN (region-based сверточная нейронная сеть). В R-CNN мы сначала сканируем входное изображение на предмет возможных объектов, используя алгоритм выборочного поиска, генерирующий ~ 2000 вариантов областей. Затем мы запускаем CNN поверх каждого из этих вариантов. Наконец, мы берем выходные данные каждого CNN и подаем его в SVM для классификации региона и линейной регрессии для ужесточения ограничивающей рамки объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn31.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, мы превратили обнаружение объектов в задачу классификации изображений. Однако есть некоторые проблемы - обучение идет медленно, требуется много места на диске, и вывод также медленный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Непосредственным потомком R-CNN является Fast R-CNN, который повышает скорость обнаружения за счет 2-х изменений: \n",
    "* 1) Выполнение извлечения признаков перед предложением областей, таким образом, работает только один CNN по всему изображению\n",
    "* 2) Замена SVM слоем softmax\n",
    "\n",
    "Bounding boxes также определяются линейной регрессией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn32.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast R-CNN показал гораздо лучшие результаты в отношении скорости, потому что по ходу обучается только одна CNN для всего изображения. Однако алгоритм выборочного поиска все еще занимает много времени для генерации интересующих регионов на изображении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, появляется Faster R-CNN, которое теперь является канонической моделью для обнаружения объектов на основе глубокого обучения. \n",
    "\n",
    "В Faster R-CNN заменяется алгоритм медленного селективного поиска быстрой нейронной сетью, добавляя Region Propocal Network (RPN) для прогнозирования регионов поиска по признакам изображения.\n",
    "\n",
    "RPN используется, чтобы решить задачу, «где» искать, чтобы уменьшить вычислительные требования всего процесса вывода. RPN быстро и эффективно сканирует каждое местоположение, чтобы оценить необходимость дальнейшей обработки в данном сегменте. Это достигается путем вывода k вариантов bounding boxes c вероятностью нахождения объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn33.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как только у нас появятся предложения по разбивочным сегментам, мы направим их прямо в то, что по сути является Fast R-CNN. Здесб находится слой пулинга, несколько полносвязных слоев и, наконец, слой классификации Softmax и регрессор для bounding boxes.\n",
    "\n",
    "В целом, Faster R-CNN достиг гораздо лучших скоростей и более высокой точности. Стоит отметить, что, хотя будущие модели многое сделали для увеличения скорости обнаружения, немногим моделям все же удалось значительно опередить Faster R-CNN. **Другими словами, Faster R-CNN, возможно, не самый простой или быстрый способ обнаружения объектов, но он все еще один из лучших.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные тенденции обнаружения объектов в последние годы сместились в сторону более быстрых и эффективных систем обнаружения.\n",
    "\n",
    "Это стало видно в таких подходах, как You Only Look Once (YOLO), Single Shot MultiBox Detector (SSD) и region-based полностью сверточные сети (R-FCN), как шаг к совместному вычислению для всего изображения. \n",
    "\n",
    "Основное обоснование этих подходов состоит в том, чтобы избежать отдельных алгоритмов на их соответствующих подзадачах, поскольку это, как правило, увеличивает время обучения и может снизить точность сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Далее YOLO и SSD\n",
    "* Настройка своего YOLO или SSD object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Литература\n",
    "\n",
    "* R-CNN https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf\n",
    "\n",
    "* Fast R-CNN https://arxiv.org/pdf/1504.08083.pdf\n",
    "\n",
    "* Faster R-CNN https://arxiv.org/pdf/1506.01497.pdf\n",
    "\n",
    "* YOLO (2016) http://lanl.arxiv.org/pdf/1612.08242v1\n",
    "\n",
    "* Single-shot SSD (2016) https://lanl.arxiv.org/pdf/1512.02325v5\n",
    "\n",
    "* R-FCN (2016) https://lanl.arxiv.org/pdf/1605.06409v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Трекинг объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отслеживание объектов относится к процессу отслеживания определенного интересующего объекта или нескольких объектов в данной сцене. Он традиционно имеет приложения для видео и реального взаимодействия, где наблюдения производятся после первоначального обнаружения объекта. \n",
    "\n",
    "Мотивация - многие компании, например, Uber и Tesla смотрят в сторону автономных систем вождения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы отслеживания объектов можно разделить на две категории в соответствии с моделью наблюдения: \n",
    "* генеративный метод\n",
    "* дискриминационный метод. \n",
    "\n",
    "Генеративный метод использует генеративную модель для описания видимых характеристик и минимизирует ошибку реконструкции для поиска объекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дискриминирующий метод может использоваться для разделения объекта и фона, его производительность более устойчива, и он постепенно становится основным методом отслеживания. \n",
    "\n",
    "**Дискриминационный метод** также называется **tracking-by-detection**, и к этой категории относится глубокое обучение. \n",
    "\n",
    "Чтобы добиться отслеживания по обнаружению (tracking-by-detection), мы обнаруживаем объекты-кандидаты для всех кадров и используем глубокое обучение для распознавания требуемого объекта из кандидатов. \n",
    "\n",
    "Существует два типа базовых сетевых моделей: \n",
    "* Stacked автоэнкодеры (SAE)\n",
    "* Сверточная нейронная сеть (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn34.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая популярная глубокая сеть для отслеживания задач с использованием SAE - это Deep Learning Tracker, который предлагает предварительное обучение в автономном режиме и тонкую настройку сети. Процесс работает так:\n",
    "\n",
    "* В офлайн режиме без учителя предварительно обучите **stacked denoising автоэнкодер** (SDAE), используя большой набор данных естественного изображения, чтобы получить общее признаковое представление объектов. Staked denosing авто-кодировщик может получить более надежную способность извлекать признаки, добавляя шум во входные изображения и восстанавливая исходные изображения.\n",
    "\n",
    "\n",
    "* Далее кодирующая часть предварительно обученного автоэнкодера соединяется с классификатором. Затем используется разметку для точной настройки сети, которая может различать текущий объект и фон.\n",
    "Deep Learning Tracker использует фильтр в качестве модели движения для создания возможных патчей (накладок) текущего (интересующего) кадра. \n",
    "Сеть классификации выводит оценки вероятности для этих пэтчей, а затем выбирает наиболее вероятные в качестве объекта.\n",
    "\n",
    "\n",
    "* При обновлении модели, DLT использует метод ограниченния порога."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за своего превосходства в классификации изображений и обнаружении объектов, CNN стала основной и в визуальном слежении.\n",
    "\n",
    "Два популряных алгоритма трекинга на основе CNN - это **полностью сверточный трекер (FCNT)** и **многодоменный CNN (MD Net).** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Convolutional Network Tracker (FCNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "FCNT анализирует и использует преимущества модели VGG извлекать признаки из изображений, которая является предварительно обученной ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCNT проектирует сеть выбора признаков для выбора наиболее релевантных карт свойств на уровнях conv4–3 и conv5–3 сети VGG. \n",
    "\n",
    "Затем, чтобы избежать переобучения, создаются два дополнительных канала (называемые SNet и GNet) для карт выбранных объектов из двух слоев отдельно. GNet собирает информацию о категории объекта (более глубокие карты conv5-3, описывающую семантику и описыв. категории, семантические признаки), в то время как SNet отличает объект от фона с похожим внешним видом (conv4-3, дискриманантные признаки, внутриклассовые различия)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn35.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-domain Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от идеи FCNT, MD Net использует все последовательности видео для отслеживания движений в них. \n",
    "\n",
    "Так как объект одного класса в этом видео может быть фоном в другом видео, в MD Net предлагается идея мультидомена, чтобы различать объект и фон в каждом домене независимо. \n",
    "\n",
    "И домен представляет собой набор видео, которые содержат объект такого же типа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как показано ниже, MD Net делится на 2 части: общие слои и K ветвей доменных слоев. \n",
    "\n",
    "Каждая ветвь содержит бинарный классификационный слой с softmax, который используется для различия объекта и фона в каждом домене, а также общие слои, используемые совместно со всеми доменами для обеспечения общего представления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn36.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последние годы исследователи глубокого обучения пробовали разные способы адаптации к особенностям задачи визуального отслеживания. Было исследовано много направлений: применение других сетевых моделей, таких как:\n",
    "* Recurrent Neural Net\n",
    "* Deep Belief Net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Далее про Deep Belief Networks\n",
    "(https://codeburst.io/deep-learning-deep-belief-network-fundamentals-d0dcfd80d7d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Литература\n",
    "\n",
    "* SDAE https://papers.nips.cc/paper/5192-learning-a-deep-compact-image-representation-for-visual-tracking.pdf\n",
    "\n",
    "* FCN tracker\n",
    "https://www.semanticscholar.org/paper/Visual-Tracking-with-Fully-Convolutional-Networks-Wang-Ouyang/328a523c0fc9a3e6ea9615fe7b9a36037a1b4f63\n",
    "\n",
    "* MD CNN https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Nam_Learning_Multi-Domain_Convolutional_CVPR_2016_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Семантическая сегментация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегментация изображения - центральная задача машинного зрения, суть которой заключается в разделение целого изображения на группы пикселей, которые можно отнести к отдному классу.\n",
    "\n",
    "В частности, семантическая сегментация пытается семантически понять роль каждого пикселя в изображении (например, это автомобиль, мотоцикл или какой-то другой класс). Например, на картинке нижу, кроме распознавания человека, также дороги, автомобилей, деревьев и т. д. \n",
    "\n",
    "Мы также должны разграничить границы каждого объекта. Поэтому, в отличие от классификации, нам нужны плотные попиксельные прогнозы на основе моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn37.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с другими задачами компьютерного зрения, CNN имели огромный успех в решении проблем сегментации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Полностью сверточными сетями (FCN)** UC Berkeley (https://arxiv.org/pdf/1411.4038.pdf), которые популяризировали сквозную архитектуру CNN для плотных попиксельных предсказаний без каких-либо полносвязных слоев. \n",
    "\n",
    "Это позволило создавать карты сегментации для изображений любого размера, а также было намного быстрее по сравнению с подходом классификации патчей.\n",
    "\n",
    "Почти все последующие подходы к семантической сегментации приняли эту парадигму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn38.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако остается одна проблема: свертки при исходном разрешении изображения вычислять очень накладко.\n",
    "\n",
    "Чтобы преодолеть это ограничение, FCN использует понижающую (**downsampling**) и повышающую (**upsampling**) дискретизацию внутри сети. Слой **понижающей дискретизации** известен как полосатая свертка (**striped convolution**), в то время как слой **повышающей дискретизации** известен как транспонированная свертка (**transposed convolution**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на upsampling и downsampling слои, FCN создает карты достаточно грубой (coarse) сегментации из-за потери информации во время пулинга (субдискретизации).\n",
    "\n",
    "**SegNet** - это более эффективная архитектура с точки зрения памяти, чем FCN, которая использует макспулинг и структуру атоэнкодера (кодировщика-декодировщика).\n",
    "\n",
    "В SegNet вводятся skip connections из карт признаков с более высоким разрешением, чтобы улучшить разрешение после upsampling/downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недавние исследования в области семантической сегментации в значительной степени основаны на полностью сверточных сетях, таких как:\n",
    "\n",
    "* Dilated Convolutions (https://arxiv.org/pdf/1511.07122.pdf)\n",
    "\n",
    "* DeepLab (https://arxiv.org/pdf/1412.7062.pdf)\n",
    "\n",
    "* RefineNet (https://arxiv.org/pdf/1611.06612.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сегментация экземпляра"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо семантической сегментации, сегментация экземпляров сегментирует различные экземпляры классов, например, маркируя 5 автомобилей 5 разными цветами. \n",
    "\n",
    "При классификации обычно используется изображение с одним объектом в качестве фокуса, и задача состоит в том, чтобы сказать, что это за изображение. \n",
    "\n",
    "Но чтобы сегментировать экземпляры, нам нужно решать гораздо более сложные задачи. \n",
    "\n",
    "Мы видим сложные изображения с несколькими перекрывающимися объектами и разными фонами, и мы не только классифицируем эти разные объекты, но и определяем их границы, различия и отношения друг к другу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn39.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До сих пор мы видели, как использовать возможности CNN, чтобы эффективно определять местоположение различных объектов на изображении с помощью ограничительных рамок (bounding boxes).\n",
    "\n",
    "Можем ли мы расширить эти подходы, чтобы найти точные пиксели каждого объекта вместо просто ограничивающих рамок?\n",
    "\n",
    "Эта проблема сегментации экземпляра решается с использованием архитектуры, известной как **Mask R-CNN**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же, как Fast R-CNN и Faster R-CNN, базовая интуиция Mask R-CNN проста. \n",
    "\n",
    "Учитывая, что Faster R-CNN так хорошо работает для обнаружения объектов, можем ли мы расширить его для выполнения сегментации на уровне пикселей?\n",
    "\n",
    "Mask R-CNN делает это, расширяя Faster R-CNN за счет дополнительной ветки, которая выводит двоичную маску, которая сообщает, является ли данный пиксель частью объекта. \n",
    "\n",
    "Блок является полностью сверточной сетью FCN поверх карты признаков изображения из CNN. Принимая в качестве входных данных карту признаков CNN, сеть выводит матрицу с 1 во всех местах, где пиксель принадлежит объекту, и 0 в других местах.\n",
    "\n",
    "Это называется **бинарной маской**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn40.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, при использовании без изменений в исходной архитектуре Faster R-CNN, регионы карты признаков, выбранные RoIPool (Region of Interests Pool), слегка смещены относительно областей исходного изображения. \n",
    "\n",
    "Поскольку сегментация изображения требует специфичности на уровне пикселей, в отличие от ограничивающих рамок, это, естественно, приводит к неточностям.\n",
    "\n",
    "Mask R-CNN решает эту проблему, настраивая RoIPool для более точного выравнивания, используя метод, известный как RoIAlign (Region of Interests Align). \n",
    "\n",
    "По сути, RoIAlign использует билинейную интерполяцию, чтобы избежать ошибок при округлении, что приводит к неточностям в детектировании и сегментации.\n",
    "\n",
    "После того как эти маски сгенерированы, Mask R-CNN объединяет их с классификациями и ограничивающими рамками из Faster R-CNN, чтобы создать такие удивительно точные сегментации:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn41.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Генерация изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генеративные состязательные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Стилизация изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основе стилизации изображений лежит ключевая идея, что возможно разделить представление стиля и представления контента в CNN, обученные в рамках задачи распознавания изображений\n",
    "\n",
    "Следуя этой концепции, для решении задачи стилизации может быть использована предобученная сверточная нейронная сеть (CNN), например, VGG 16, для переноса стиля от одного изображения на другое.\n",
    "\n",
    "Это делается путем определения функции потерь, которая пытается минимизировать различия между изображением контента, изображением стиля и сгенерированным изображением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn42.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Задача transer learning на основе VGG 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Литература:\n",
    "\n",
    "https://heartbeat.fritz.ai/20-minute-masterpiece-4b6043fdfff5\n",
    "\n",
    "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Идентификация позы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn45.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идентификация позы относится к методам компьютерного зрения, которые обнаруживают скелетон человека на изображении. Алгоритм оценивает, где находятся ключевые суставы тела. При этом не обеспечивает идентификацию самого человека"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoseNet может использоваться для оценки одной или нескольких поз, что означает, что существует версия алгоритма, которая может обнаруживать только одного человека на изображении / видео, и одна версия, которая может обнаруживать несколько человек на изображении.\n",
    "\n",
    "Почему есть две версии? \n",
    "\n",
    "Детектор позы для одного человека работает быстрее и проще, но требует только одного объекта, присутствующего на изображении (подробнее об этом позже). \n",
    "\n",
    "Сначала мы расскажем об одиночной позе, потому что за ней легче следовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Верхнеуровнево идентификация позы происходит в два этапа:\n",
    "\n",
    "* Входное RGB-изображение подается через сверточную нейронную сеть.\n",
    "\n",
    "* Алгоритм декодирования используется для декодирования поз, оценок достоверности поз, позиций ключевых точек и оценок достоверности ключевых точек из выходных данных модели.\n",
    "\n",
    "**Pose** на самом высоком уровне PoseNet - это объект позы, который содержит список ключевых точек и показатель достоверности на уровне экземпляра для каждого обнаруженного человека."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Оценка уверенности (pose confidence score)** - определяет общую уверенность в оценке позы. Он колеблется между 0,0 и 1,0. Его можно использовать, чтобы скрыть позы, которые не считаются достаточно уверенно распознанными.\n",
    "\n",
    "* **Ключевая точка (keypoint)** - оцениваемая часть позы человека, такая как нос, правое ухо, левое колено, правая ступня и т. д. Она содержит как позицию, так и оценку достоверности ключевой точки. В настоящее время PoseNet обнаруживает 17 ключевых точек, показанных на следующей диаграмме ниже.\n",
    "\n",
    "* **Оценка достоверности ключевой точки (keypoint CS)** - это определяет уверенность в том, что оценочная позиция ключевой точки является точной. Он колеблется между 0,0 и 1,0. Его можно использовать, чтобы скрыть ключевые точки, которые не считаются достаточно достоверными\n",
    "\n",
    "* **Положение ключевой точки (keypoint position)** - 2D координаты x и y в исходном входном изображении, где обнаружена ключевая точка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn44.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна важная деталь, на которую следует обратить внимание, заключается в том, что исследователи обучили ResNet MobileNet версии PoseNet. \n",
    "\n",
    "Хотя модель ResNet обладает более высокой точностью, ее большой размер и множество слоев делают время загрузки страницы и время вывода менее чем идеальным для любых приложений в real-time. \n",
    "\n",
    "В данный момент большинство использует модель MobileNet, так как она разработана для работы на мобильных устройствах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача обучения детектировать действие**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Литература:\n",
    "    \n",
    "https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
