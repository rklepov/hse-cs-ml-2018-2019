{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "САД NLP 6 | MT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BpzBeBXxYcZJ",
        "iTndjb7j4w8Z",
        "ohcx-y4M_ptR"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oserikov/data-science-nlp/blob/master/6_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D1%8B%D0%B9_%D0%BF%D0%B5%D1%80%D0%B5%D0%B2%D0%BE%D0%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpzBeBXxYcZJ",
        "colab_type": "text"
      },
      "source": [
        "# Машинный перевод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTndjb7j4w8Z",
        "colab_type": "text"
      },
      "source": [
        "## Apertium"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWu5i8d14yjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "e802edcc-4912-4673-a3e7-7d4888c088d0"
      },
      "source": [
        "!pip install apertium"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting apertium\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/0a/b75646773a53aa8318ecb164b2d9e39889cf458097b67abd6cc6dba0b9dc/apertium-0.2.3.tar.gz\n",
            "Collecting apertium-streamparser==5.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ca/47/85027843345b1d7e4d0beca98c3c55ac8bb1b2d9069a126877b645be481c/apertium_streamparser-5.0.2-py3-none-any.whl\n",
            "Building wheels for collected packages: apertium\n",
            "  Building wheel for apertium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apertium: filename=apertium-0.2.3-cp36-none-any.whl size=14709 sha256=943073f9c175b2a1af0c99273b92bf4401c79fcd45908470673c9623c7864e67\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/76/ee/f4ba561c990f737cdb36ab1bff6c7676bd23d4ed4cc8cef9a0\n",
            "Successfully built apertium\n",
            "Installing collected packages: apertium-streamparser, apertium\n",
            "Successfully installed apertium-0.2.3 apertium-streamparser-5.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Z1pMON5kMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import apertium"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm5xAy6S8RCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apertium.install_module(\"fra-cat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABhxjbKa-uR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apertium.append_pair_path(\"/usr/share/apertium/modes/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UHNXJu860Lq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dbe507b-4c30-43ca-bc4a-3372ed9e0de9"
      },
      "source": [
        "apertium.translate('fra', 'cat', 'je suis étudiant')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sóc estudiant'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohcx-y4M_ptR",
        "colab_type": "text"
      },
      "source": [
        "## OpenNMT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF8hmLkFYpZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOWAiJ_VKqbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "10e7d7ee-bcf4-40b7-8a6b-b3fe7b30b248"
      },
      "source": [
        "!apt install sox libsox-dev libsox-fmt-all\n",
        "!apt install libasound2-plugins libasound2-python libsox-fmt-all libsox-dev sox\n",
        "\n",
        "!git clone https://github.com/pytorch/audio.git\n",
        "%cd audio\n",
        "!git checkout 301e2e9\n",
        "!python setup.py install\n",
        "%cd ..\n",
        "!pip install -r OpenNMT-py/requirements.opt.txt\n",
        "!pip install configargparse\n",
        "!pip uninstall -y torchtext\n",
        "!pip install git+https://github.com/pytorch/text\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.0+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TMLLRab_xWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "651d84d5-16a9-4378-e1ee-b5fa0801ce55"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus/master/Multilingual_Parallel_Corpus/Multi_lingual_Parallel_corpus_1.zip\n",
        "!unzip -q Multi_lingual_Parallel_corpus_1.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-07 08:39:51--  https://raw.githubusercontent.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus/master/Multilingual_Parallel_Corpus/Multi_lingual_Parallel_corpus_1.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78542347 (75M) [application/zip]\n",
            "Saving to: ‘Multi_lingual_Parallel_corpus_1.zip’\n",
            "\n",
            "Multi_lingual_Paral 100%[===================>]  74.90M   156MB/s    in 0.5s    \n",
            "\n",
            "2019-11-07 08:39:54 (156 MB/s) - ‘Multi_lingual_Parallel_corpus_1.zip’ saved [78542347/78542347]\n",
            "\n",
            "--2019-11-07 08:39:55--  https://raw.githubusercontent.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus/master/Multilingual_Parallel_Corpus/Multi_lingual_Parallel_corpus_2.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34432048 (33M) [application/zip]\n",
            "Saving to: ‘Multi_lingual_Parallel_corpus_2.zip’\n",
            "\n",
            "Multi_lingual_Paral 100%[===================>]  32.84M   127MB/s    in 0.3s    \n",
            "\n",
            "2019-11-07 08:39:57 (127 MB/s) - ‘Multi_lingual_Parallel_corpus_2.zip’ saved [34432048/34432048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbS9q_y3BuBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "0e4110f7-015c-4ca6-88a0-fce7928b7f8a"
      },
      "source": [
        "!head Multilingual_Parllel_corpus.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:ar:بالنسبة لي، تبدأ هذه القصة قبل حوالي 15 عاماً مضت،\n",
            "1:nl:Voor mij begint dit verhaal ongeveer 15 jaar geleden,\n",
            "1:fr:Pour moi, cette histoire a commencé il y a 15 ans,\n",
            "1:de:Für mich beginnt diese Geschichte vor ungefähr 15 Jahren,\n",
            "1:he:עבורי, הסיפור הזה התחיל בערך לפני 15 שנים,\n",
            "1:it:Per me, questa storia inizia circa 15 anni fa,\n",
            "1:ru:Для меня всё началось лет 15 тому назад, когда я работал врачом\n",
            "1:es:Para mí esta historia comienza hace 15 años\n",
            "1:ar:بالنسبة لي، تبدأ هذه القصة قبل حوالي 15 عاماً مضت،\n",
            "1:pt-br:Para mim, esta história começa cerca de 15 anos atrás,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoLeeT6mBwmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!grep -P \"^\\d+:ru\" Multilingual_Parllel_corpus.txt | \\\n",
        " sed -e \"s|[0-9]\\+:ru:||\" \\\n",
        " > ru_sentences.txt\n",
        "\n",
        "!grep -P \"^\\d+:fr\" Multilingual_Parllel_corpus.txt | \\\n",
        " sed -e \"s|[0-9]\\+:fr:||\" \\\n",
        " > fr_sentences.txt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shjD6QH-C0Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train test val split\n",
        "fr_sentences_wc_l = !wc -l fr_sentences.txt\n",
        "fr_sentences_num = int(fr_sentences_wc_l[0].split()[0])\n",
        "\n",
        "import math\n",
        "\n",
        "train_sentences_num = math.floor(fr_sentences_num * 0.7)\n",
        "test_sentences_num = math.floor(fr_sentences_num * 0.2)\n",
        "val_sentences_num = fr_sentences_num - train_sentences_num - test_sentences_num\n",
        "\n",
        "!head -{train_sentences_num} ru_sentences.txt > ru_sentences_train.txt\n",
        "!head -{train_sentences_num} fr_sentences.txt > fr_sentences_train.txt\n",
        "\n",
        "!head -{train_sentences_num+test_sentences_num} ru_sentences.txt | \\\n",
        " tail -{test_sentences_num} > ru_sentences_test.txt\n",
        "!head -{train_sentences_num+test_sentences_num} fr_sentences.txt | \\\n",
        " tail -{test_sentences_num} > fr_sentences_test.txt\n",
        "\n",
        "!tail -{val_sentences_num} ru_sentences.txt > ru_sentences_val.txt\n",
        "!tail -{val_sentences_num} fr_sentences.txt > fr_sentences_val.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sxb_BtTF3fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn bpe\n",
        "!python OpenNMT-py/tools/learn_bpe.py \\\n",
        " -i ru_sentences_train.txt -o ru_sentences_train.code -s 10000\n",
        "\n",
        "!python OpenNMT-py/tools/learn_bpe.py \\\n",
        " -i fr_sentences_train.txt -o fr_sentences_train.code -s 10000\n",
        "\n",
        "# apply bpe to source sentences\n",
        "!python OpenNMT-py/tools/apply_bpe.py \\\n",
        " -c ru_sentences_train.code \\\n",
        " -i ru_sentences_train.txt \\\n",
        " -o ru_sentences_train_bpe.txt\n",
        "\n",
        "!python OpenNMT-py/tools/apply_bpe.py \\\n",
        " -c ru_sentences_train.code \\\n",
        " -i ru_sentences_test.txt \\\n",
        " -o ru_sentences_test_bpe.txt\n",
        "\n",
        "!python OpenNMT-py/tools/apply_bpe.py \\\n",
        " -c ru_sentences_train.code \\\n",
        " -i ru_sentences_val.txt \\\n",
        " -o ru_sentences_val_bpe.txt\n",
        "\n",
        "# apply bpe to target sentences\n",
        "!python OpenNMT-py/tools/apply_bpe.py \\\n",
        " -c fr_sentences_train.code \\\n",
        " -i fr_sentences_train.txt \\\n",
        " -o fr_sentences_train_bpe.txt\n",
        "\n",
        "!python OpenNMT-py/tools/apply_bpe.py \\\n",
        " -c fr_sentences_train.code \\\n",
        " -i fr_sentences_test.txt \\\n",
        " -o fr_sentences_test_bpe.txt\n",
        "\n",
        "!python OpenNMT-py/tools/apply_bpe.py \\\n",
        " -c fr_sentences_train.code \\\n",
        " -i fr_sentences_val.txt \\\n",
        " -o fr_sentences_val_bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJag-CucHexJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "4d85005f-b1a5-44d9-de4f-85e64fff91a1"
      },
      "source": [
        "!mkdir saved_data\n",
        "!python OpenNMT-py/preprocess.py \\\n",
        " -train_src ru_sentences_train_bpe.txt \\\n",
        " -train_tgt fr_sentences_train_bpe.txt \\\n",
        " -valid_src ru_sentences_val_bpe.txt \\\n",
        " -valid_tgt fr_sentences_val_bpe.txt \\\n",
        " -save_data saved_data/"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘saved_data’: File exists\n",
            "[2019-11-07 09:36:17,037 INFO] Extracting features...\n",
            "[2019-11-07 09:36:17,037 INFO]  * number of source features: 0.\n",
            "[2019-11-07 09:36:17,037 INFO]  * number of target features: 0.\n",
            "[2019-11-07 09:36:17,037 INFO] Building `Fields` object...\n",
            "[2019-11-07 09:36:17,037 INFO] Building & saving training data...\n",
            "[2019-11-07 09:36:17,416 INFO] Building shard 0.\n",
            "[2019-11-07 09:36:26,957 INFO]  * saving 0th train data shard to saved_data/.train.0.pt.\n",
            "[2019-11-07 09:36:34,162 INFO]  * tgt vocab size: 10243.\n",
            "[2019-11-07 09:36:34,213 INFO]  * src vocab size: 10320.\n",
            "[2019-11-07 09:36:34,271 INFO] Building & saving validation data...\n",
            "[2019-11-07 09:36:34,375 INFO] Building shard 0.\n",
            "[2019-11-07 09:36:35,124 INFO]  * saving 0th valid data shard to saved_data/.valid.0.pt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSk0P4KIZL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06252aac-2080-4e51-cdd6-94fb017c0a8c"
      },
      "source": [
        "!mkdir saved_model\n",
        "!python OpenNMT-py/train.py \\\n",
        " -data saved_data/ \\\n",
        " -save_model saved_model/ \\\n",
        " -layers 6 -rnn_size 512 -word_vec_size 512 \\\n",
        " -transformer_ff 2048 \\\n",
        " -heads 8 \\\n",
        " -encoder_type transformer -decoder_type transformer \\\n",
        " -position_encoding \\\n",
        " -train_steps 200000 \\\n",
        " -max_generator_batches 2 \\\n",
        " -dropout 0.1 \\\n",
        " -batch_size 4096 -batch_type tokens \\\n",
        " -normalization tokens \\\n",
        " -accum_count 2 \\\n",
        " -optim adam -adam_beta2 0.998 \\\n",
        " -decay_method noam \\\n",
        " -warmup_steps 8000 \\\n",
        " -learning_rate 2 \\\n",
        " -max_grad_norm 0 \\\n",
        " -param_init 0 -param_init_glorot \\\n",
        " -label_smoothing 0.1 \\\n",
        " -valid_steps 1000 -save_checkpoint_steps 1000 \\\n",
        " -world_size 1 -gpu_rank 0"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘saved_model’: File exists\n",
            "[2019-11-07 09:37:05,378 INFO]  * src vocab size = 10320\n",
            "[2019-11-07 09:37:05,379 INFO]  * tgt vocab size = 10243\n",
            "[2019-11-07 09:37:05,379 INFO] Building model...\n",
            "[2019-11-07 09:37:14,757 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10320, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10243, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=10243, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2019-11-07 09:37:14,818 INFO] encoder: 24199168\n",
            "[2019-11-07 09:37:14,819 INFO] decoder: 35724291\n",
            "[2019-11-07 09:37:14,819 INFO] * number of parameters: 59923459\n",
            "[2019-11-07 09:37:14,822 INFO] Starting training on GPU: [0]\n",
            "[2019-11-07 09:37:14,822 INFO] Start training loop and validate every 1000 steps...\n",
            "[2019-11-07 09:37:14,823 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 09:37:17,941 INFO] number of examples: 244331\n",
            "[2019-11-07 09:37:46,546 INFO] Step 50/200000; acc:   4.77; ppl: 2521.90; xent: 7.83; lr: 0.00001; 9097/11595 tok/s;     32 sec\n",
            "[2019-11-07 09:38:12,436 INFO] Step 100/200000; acc:   9.02; ppl: 1581.97; xent: 7.37; lr: 0.00001; 10800/13897 tok/s;     58 sec\n",
            "[2019-11-07 09:38:38,542 INFO] Step 150/200000; acc:   9.18; ppl: 1173.78; xent: 7.07; lr: 0.00002; 10867/13610 tok/s;     84 sec\n",
            "[2019-11-07 09:39:04,556 INFO] Step 200/200000; acc:   9.58; ppl: 834.24; xent: 6.73; lr: 0.00002; 11016/13830 tok/s;    110 sec\n",
            "[2019-11-07 09:39:30,430 INFO] Step 250/200000; acc:   9.07; ppl: 629.34; xent: 6.44; lr: 0.00003; 10738/13332 tok/s;    136 sec\n",
            "[2019-11-07 09:39:56,482 INFO] Step 300/200000; acc:   9.34; ppl: 503.70; xent: 6.22; lr: 0.00004; 10831/13698 tok/s;    162 sec\n",
            "[2019-11-07 09:40:22,409 INFO] Step 350/200000; acc:  10.47; ppl: 430.08; xent: 6.06; lr: 0.00004; 10792/13655 tok/s;    188 sec\n",
            "[2019-11-07 09:40:33,044 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 09:40:36,771 INFO] number of examples: 244331\n",
            "[2019-11-07 09:40:54,781 INFO] Step 400/200000; acc:  10.90; ppl: 408.27; xent: 6.01; lr: 0.00005; 8905/11296 tok/s;    220 sec\n",
            "[2019-11-07 09:41:20,961 INFO] Step 450/200000; acc:  10.72; ppl: 386.90; xent: 5.96; lr: 0.00006; 11026/13778 tok/s;    246 sec\n",
            "[2019-11-07 09:41:47,008 INFO] Step 500/200000; acc:  11.04; ppl: 354.11; xent: 5.87; lr: 0.00006; 10842/13719 tok/s;    272 sec\n",
            "[2019-11-07 09:42:13,183 INFO] Step 550/200000; acc:  12.23; ppl: 294.65; xent: 5.69; lr: 0.00007; 10664/13830 tok/s;    298 sec\n",
            "[2019-11-07 09:42:39,034 INFO] Step 600/200000; acc:  13.27; ppl: 248.73; xent: 5.52; lr: 0.00007; 11082/13798 tok/s;    324 sec\n",
            "[2019-11-07 09:43:05,031 INFO] Step 650/200000; acc:  14.21; ppl: 221.60; xent: 5.40; lr: 0.00008; 10695/13183 tok/s;    350 sec\n",
            "[2019-11-07 09:43:31,162 INFO] Step 700/200000; acc:  15.09; ppl: 194.84; xent: 5.27; lr: 0.00009; 10616/13696 tok/s;    376 sec\n",
            "[2019-11-07 09:43:52,576 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 09:43:56,252 INFO] number of examples: 244331\n",
            "[2019-11-07 09:44:03,149 INFO] Step 750/200000; acc:  16.28; ppl: 170.83; xent: 5.14; lr: 0.00009; 9022/11253 tok/s;    408 sec\n",
            "[2019-11-07 09:44:29,522 INFO] Step 800/200000; acc:  16.51; ppl: 157.10; xent: 5.06; lr: 0.00010; 10860/13811 tok/s;    435 sec\n",
            "[2019-11-07 09:44:55,565 INFO] Step 850/200000; acc:  17.56; ppl: 139.29; xent: 4.94; lr: 0.00011; 11064/13897 tok/s;    461 sec\n",
            "[2019-11-07 09:45:21,700 INFO] Step 900/200000; acc:  18.43; ppl: 125.93; xent: 4.84; lr: 0.00011; 10742/13715 tok/s;    487 sec\n",
            "[2019-11-07 09:45:47,435 INFO] Step 950/200000; acc:  19.64; ppl: 111.40; xent: 4.71; lr: 0.00012; 11008/13804 tok/s;    513 sec\n",
            "[2019-11-07 09:46:13,527 INFO] Step 1000/200000; acc:  19.25; ppl: 109.16; xent: 4.69; lr: 0.00012; 10813/13344 tok/s;    539 sec\n",
            "[2019-11-07 09:46:13,529 INFO] Loading dataset from saved_data/.valid.0.pt\n",
            "[2019-11-07 09:46:14,422 INFO] number of examples: 34906\n",
            "[2019-11-07 09:46:43,414 INFO] Validation perplexity: 200.102\n",
            "[2019-11-07 09:46:43,414 INFO] Validation accuracy: 20.4212\n",
            "[2019-11-07 09:46:43,489 INFO] Saving checkpoint saved_model/_step_1000.pt\n",
            "[2019-11-07 09:47:11,899 INFO] Step 1050/200000; acc:  20.57; ppl: 96.89; xent: 4.57; lr: 0.00013; 4808/6069 tok/s;    597 sec\n",
            "[2019-11-07 09:47:37,884 INFO] Step 1100/200000; acc:  21.19; ppl: 89.19; xent: 4.49; lr: 0.00014; 10876/13758 tok/s;    623 sec\n",
            "[2019-11-07 09:47:43,742 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 09:47:47,862 INFO] number of examples: 244331\n",
            "[2019-11-07 09:48:10,660 INFO] Step 1150/200000; acc:  22.24; ppl: 80.14; xent: 4.38; lr: 0.00014; 8782/11227 tok/s;    656 sec\n",
            "[2019-11-07 09:48:36,691 INFO] Step 1200/200000; acc:  22.06; ppl: 78.94; xent: 4.37; lr: 0.00015; 10937/13748 tok/s;    682 sec\n",
            "[2019-11-07 09:49:02,701 INFO] Step 1250/200000; acc:  22.85; ppl: 72.85; xent: 4.29; lr: 0.00015; 10840/13664 tok/s;    708 sec\n",
            "[2019-11-07 09:49:28,758 INFO] Step 1300/200000; acc:  23.89; ppl: 66.33; xent: 4.19; lr: 0.00016; 10963/13898 tok/s;    734 sec\n",
            "[2019-11-07 09:49:54,617 INFO] Step 1350/200000; acc:  25.07; ppl: 60.72; xent: 4.11; lr: 0.00017; 10826/13657 tok/s;    760 sec\n",
            "[2019-11-07 09:50:20,645 INFO] Step 1400/200000; acc:  24.52; ppl: 60.92; xent: 4.11; lr: 0.00017; 10695/13390 tok/s;    786 sec\n",
            "[2019-11-07 09:50:46,539 INFO] Step 1450/200000; acc:  25.84; ppl: 54.96; xent: 4.01; lr: 0.00018; 10753/13751 tok/s;    812 sec\n",
            "[2019-11-07 09:51:03,411 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 09:51:06,607 INFO] number of examples: 244331\n",
            "[2019-11-07 09:51:18,222 INFO] Step 1500/200000; acc:  27.30; ppl: 50.27; xent: 3.92; lr: 0.00019; 9180/11407 tok/s;    843 sec\n",
            "[2019-11-07 09:51:44,562 INFO] Step 1550/200000; acc:  26.71; ppl: 50.32; xent: 3.92; lr: 0.00019; 10820/13885 tok/s;    870 sec\n",
            "[2019-11-07 09:52:10,542 INFO] Step 1600/200000; acc:  27.49; ppl: 47.27; xent: 3.86; lr: 0.00020; 11100/13730 tok/s;    896 sec\n",
            "[2019-11-07 09:52:36,801 INFO] Step 1650/200000; acc:  28.63; ppl: 43.76; xent: 3.78; lr: 0.00020; 10819/13810 tok/s;    922 sec\n",
            "[2019-11-07 09:53:02,522 INFO] Step 1700/200000; acc:  29.39; ppl: 41.54; xent: 3.73; lr: 0.00021; 10891/13597 tok/s;    948 sec\n",
            "[2019-11-07 09:53:28,585 INFO] Step 1750/200000; acc:  29.44; ppl: 40.77; xent: 3.71; lr: 0.00022; 10701/13528 tok/s;    974 sec\n",
            "[2019-11-07 09:53:54,555 INFO] Step 1800/200000; acc:  30.11; ppl: 38.33; xent: 3.65; lr: 0.00022; 10694/13699 tok/s;   1000 sec\n",
            "[2019-11-07 09:54:20,761 INFO] Step 1850/200000; acc:  31.51; ppl: 35.18; xent: 3.56; lr: 0.00023; 11027/13587 tok/s;   1026 sec\n",
            "[2019-11-07 09:54:21,858 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 09:54:25,875 INFO] number of examples: 244331\n",
            "[2019-11-07 09:54:53,512 INFO] Step 1900/200000; acc:  31.80; ppl: 33.62; xent: 3.52; lr: 0.00023; 8849/11223 tok/s;   1059 sec\n",
            "[2019-11-07 09:55:19,395 INFO] Step 1950/200000; acc:  31.55; ppl: 34.03; xent: 3.53; lr: 0.00024; 10753/13938 tok/s;   1085 sec\n",
            "[2019-11-07 09:55:45,534 INFO] Step 2000/200000; acc:  32.35; ppl: 32.12; xent: 3.47; lr: 0.00025; 10969/13607 tok/s;   1111 sec\n",
            "[2019-11-07 09:55:45,536 INFO] Loading dataset from saved_data/.valid.0.pt\n",
            "[2019-11-07 09:55:47,173 INFO] number of examples: 34906\n",
            "[2019-11-07 09:56:16,313 INFO] Validation perplexity: 51.601\n",
            "[2019-11-07 09:56:16,313 INFO] Validation accuracy: 32.746\n",
            "[2019-11-07 09:56:16,387 INFO] Saving checkpoint saved_model/_step_2000.pt\n",
            "[2019-11-07 09:56:44,870 INFO] Step 2050/200000; acc:  33.97; ppl: 28.90; xent: 3.36; lr: 0.00025; 4845/6075 tok/s;   1170 sec\n",
            "[2019-11-07 09:57:10,795 INFO] Step 2100/200000; acc:  34.03; ppl: 28.85; xent: 3.36; lr: 0.00026; 10609/13397 tok/s;   1196 sec\n",
            "[2019-11-07 09:57:36,883 INFO] Step 2150/200000; acc:  34.19; ppl: 27.85; xent: 3.33; lr: 0.00027; 10834/13645 tok/s;   1222 sec\n",
            "[2019-11-07 09:58:02,698 INFO] Step 2200/200000; acc:  35.01; ppl: 26.36; xent: 3.27; lr: 0.00027; 10788/13595 tok/s;   1248 sec\n",
            "[2019-11-07 09:58:14,872 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 09:58:22,156 INFO] number of examples: 244331\n",
            "[2019-11-07 09:58:38,694 INFO] Step 2250/200000; acc:  35.95; ppl: 24.84; xent: 3.21; lr: 0.00028; 8045/10118 tok/s;   1284 sec\n",
            "[2019-11-07 09:59:04,888 INFO] Step 2300/200000; acc:  35.44; ppl: 25.19; xent: 3.23; lr: 0.00028; 10986/13826 tok/s;   1310 sec\n",
            "[2019-11-07 09:59:30,965 INFO] Step 2350/200000; acc:  35.80; ppl: 24.34; xent: 3.19; lr: 0.00029; 10914/13764 tok/s;   1336 sec\n",
            "[2019-11-07 09:59:57,032 INFO] Step 2400/200000; acc:  36.92; ppl: 22.76; xent: 3.13; lr: 0.00030; 10606/13921 tok/s;   1362 sec\n",
            "[2019-11-07 10:00:22,754 INFO] Step 2450/200000; acc:  37.59; ppl: 21.81; xent: 3.08; lr: 0.00030; 11208/13712 tok/s;   1388 sec\n",
            "[2019-11-07 10:00:48,811 INFO] Step 2500/200000; acc:  37.30; ppl: 21.93; xent: 3.09; lr: 0.00031; 10626/13310 tok/s;   1414 sec\n",
            "[2019-11-07 10:01:14,890 INFO] Step 2550/200000; acc:  37.61; ppl: 21.26; xent: 3.06; lr: 0.00032; 10712/13724 tok/s;   1440 sec\n",
            "[2019-11-07 10:01:37,372 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 10:01:40,662 INFO] number of examples: 244331\n",
            "[2019-11-07 10:01:46,558 INFO] Step 2600/200000; acc:  38.94; ppl: 19.79; xent: 2.99; lr: 0.00032; 9084/11309 tok/s;   1472 sec\n",
            "[2019-11-07 10:02:12,872 INFO] Step 2650/200000; acc:  38.57; ppl: 19.82; xent: 2.99; lr: 0.00033; 11036/13870 tok/s;   1498 sec\n",
            "[2019-11-07 10:02:38,891 INFO] Step 2700/200000; acc:  38.64; ppl: 19.66; xent: 2.98; lr: 0.00033; 10816/13902 tok/s;   1524 sec\n",
            "[2019-11-07 10:03:05,018 INFO] Step 2750/200000; acc:  39.19; ppl: 19.03; xent: 2.95; lr: 0.00034; 10856/13701 tok/s;   1550 sec\n",
            "[2019-11-07 10:03:30,651 INFO] Step 2800/200000; acc:  40.45; ppl: 17.60; xent: 2.87; lr: 0.00035; 11026/13795 tok/s;   1576 sec\n",
            "[2019-11-07 10:03:56,792 INFO] Step 2850/200000; acc:  39.73; ppl: 18.20; xent: 2.90; lr: 0.00035; 10818/13362 tok/s;   1602 sec\n",
            "[2019-11-07 10:04:22,800 INFO] Step 2900/200000; acc:  40.31; ppl: 17.49; xent: 2.86; lr: 0.00036; 10837/13721 tok/s;   1628 sec\n",
            "[2019-11-07 10:04:48,700 INFO] Step 2950/200000; acc:  40.60; ppl: 17.09; xent: 2.84; lr: 0.00036; 10712/13721 tok/s;   1654 sec\n",
            "[2019-11-07 10:04:56,146 INFO] Loading dataset from saved_data/.train.0.pt\n",
            "[2019-11-07 10:05:00,143 INFO] number of examples: 244331\n",
            "[2019-11-07 10:05:21,336 INFO] Step 3000/200000; acc:  41.89; ppl: 15.99; xent: 2.77; lr: 0.00037; 8851/11207 tok/s;   1687 sec\n",
            "[2019-11-07 10:05:21,337 INFO] Loading dataset from saved_data/.valid.0.pt\n",
            "[2019-11-07 10:05:22,997 INFO] number of examples: 34906\n",
            "[2019-11-07 10:05:52,060 INFO] Validation perplexity: 29.4539\n",
            "[2019-11-07 10:05:52,061 INFO] Validation accuracy: 39.1362\n",
            "[2019-11-07 10:05:52,135 INFO] Saving checkpoint saved_model/_step_3000.pt\n",
            "[2019-11-07 10:06:20,632 INFO] Step 3050/200000; acc:  41.15; ppl: 16.51; xent: 2.80; lr: 0.00038; 4853/6037 tok/s;   1746 sec\n",
            "[2019-11-07 10:06:46,638 INFO] Step 3100/200000; acc:  40.87; ppl: 16.56; xent: 2.81; lr: 0.00038; 10824/13786 tok/s;   1772 sec\n",
            "Traceback (most recent call last):\n",
            "  File \"OpenNMT-py/train.py\", line 6, in <module>\n",
            "    main()\n",
            "  File \"/content/OpenNMT-py/onmt/bin/train.py\", line 200, in main\n",
            "    train(opt)\n",
            "  File \"/content/OpenNMT-py/onmt/bin/train.py\", line 86, in train\n",
            "    single_main(opt, 0)\n",
            "  File \"/content/OpenNMT-py/onmt/train_single.py\", line 143, in main\n",
            "    valid_steps=opt.valid_steps)\n",
            "  File \"/content/OpenNMT-py/onmt/trainer.py\", line 243, in train\n",
            "    report_stats)\n",
            "  File \"/content/OpenNMT-py/onmt/trainer.py\", line 370, in _gradient_accumulation\n",
            "    trunc_size=trunc_size)\n",
            "  File \"/content/OpenNMT-py/onmt/utils/loss.py\", line 164, in __call__\n",
            "    for shard in shards(shard_state, shard_size):\n",
            "  File \"/content/OpenNMT-py/onmt/utils/loss.py\", line 338, in shards\n",
            "    torch.autograd.backward(inputs, grads)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFgMhB1TVXAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir saved_model\n",
        "!python OpenNMT-py/train.py \\\n",
        " -data saved_data/ \\\n",
        " -save_model saved_model/ \\\n",
        " -layers 6 -rnn_size 512 -word_vec_size 512 \\\n",
        " -transformer_ff 2048 \\\n",
        " -heads 8 \\\n",
        " -encoder_type transformer -decoder_type transformer \\\n",
        " -position_encoding \\\n",
        " -train_steps 200000 \\\n",
        " -max_generator_batches 2 \\\n",
        " -dropout 0.1 \\\n",
        " -batch_size 4096 -batch_type tokens \\\n",
        " -normalization tokens \\\n",
        " -accum_count 2 \\\n",
        " -optim adam -adam_beta2 0.998 \\\n",
        " -decay_method noam \\\n",
        " -warmup_steps 8000 \\\n",
        " -learning_rate 2 \\\n",
        " -max_grad_norm 0 \\\n",
        " -param_init 0 -param_init_glorot \\\n",
        " -label_smoothing 0.1 \\\n",
        " -valid_steps 1000 -save_checkpoint_steps 1000 \\\n",
        " -world_size 1 -gpu_rank 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqytUBFyVjc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "outputId": "cef1f4b9-b20e-425f-e5d2-ed5be7454e49"
      },
      "source": [
        "!python OpenNMT-py/translate.py \\\n",
        " -model saved_model/_step_3000.pt \\\n",
        " -src ru_sentences_val_bpe.txt \\\n",
        " -output pred.txt \\\n",
        " -replace_unk \\\n",
        "# -verbose\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2019-11-07 10:12:37,368 INFO] Translating shard 0.\n",
            "Traceback (most recent call last):\n",
            "  File \"OpenNMT-py/translate.py\", line 6, in <module>\n",
            "    main()\n",
            "  File \"/content/OpenNMT-py/onmt/bin/translate.py\", line 49, in main\n",
            "    translate(opt)\n",
            "  File \"/content/OpenNMT-py/onmt/bin/translate.py\", line 33, in translate\n",
            "    attn_debug=opt.attn_debug\n",
            "  File \"/content/OpenNMT-py/onmt/translate/translator.py\", line 351, in translate\n",
            "    batch, data.src_vocabs, attn_debug\n",
            "  File \"/content/OpenNMT-py/onmt/translate/translator.py\", line 544, in translate_batch\n",
            "    return_attention=attn_debug or self.replace_unk)\n",
            "  File \"/content/OpenNMT-py/onmt/translate/translator.py\", line 694, in _translate_batch\n",
            "    batch_offset=beam._batch_offset)\n",
            "  File \"/content/OpenNMT-py/onmt/translate/translator.py\", line 582, in _decode_and_generate\n",
            "    decoder_in, memory_bank, memory_lengths=memory_lengths, step=step\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
            "  File \"/content/OpenNMT-py/onmt/decoders/transformer.py\", line 226, in forward\n",
            "    step=step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/OpenNMT-py/onmt/decoders/transformer.py\", line 84, in forward\n",
            "    attn_type=\"self\")\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/OpenNMT-py/onmt/modules/multi_headed_attn.py\", line 187, in forward\n",
            "    query = query / math.sqrt(dim_per_head)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImNuR_rGWev_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bbe1814-43ce-4fd9-a770-8ee25a902c24"
      },
      "source": [
        "!paste \\\n",
        " <(sed \"s|@@ ||g\" ru_sentences_val_bpe.txt | head -100) \\\n",
        " <(sed \"s|@@ ||g\" pred.txt | head -100) \\\n",
        " | column -t -s $'\\t'"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "относящихся к инфицированным ВИЧ,                              qui sont infectés par le VIH,\n",
            "но и о людях в группе                                          mais aussi aux gens\n",
            "об употребляющих наркотики,                                    de la drogue,\n",
            "о мужчинах,                                                    des hommes\n",
            "о трансгендерах,                                               de la transplantation,\n",
            "о мигрантах и заключённых.                                     sur le point de vue et en revenir.\n",
            "И во многих частях света эта группа                            Et dans beaucoup de parties du monde,\n",
            "которые особенно уязвимы.                                      qui sont particulièrement vulnérables.\n",
            "Во многих частях света есть законы,                            Il y a de nombreuses parties du monde,\n",
            "отражающие лучшую часть человеческой натуры.                   la meilleure partie de la nature humaine.\n",
            "Эти законы относятся к людям с ВИЧ                             Ces règles du VIH\n",
            "с сочувствием и без отторжения.                                avec la compassion et sans dépression.\n",
            "Эти законы уважают                                             Ces règles sont respectées\n",
            "и основаны на научных знаниях.                                 et sont basés sur les scientifiques,\n",
            "Эти законы гарантируют,                                        Ce sont des lois\n",
            "также как и находящиеся                                        aussi que les gens\n",
            "защищены от насилия и дискриминации,                           de la violence et de la violence\n",
            "что у них есть доступ                                          qu'ils ont accès à un accès\n",
            "К сожалению, эти хорошие законы                                Malheureusement, ces bonnes choses\n",
            "уравновешиваются массой                                        sont équilibrés\n",
            "очень плохих законов.                                          est très mauvaise réponse.\n",
            "Законов, основанных на моральных суждениях,                    Les réformes de moralité\n",
            "страхе и заблуждениях.                                         la peur et la peur,\n",
            "Законов, специально карающих людей с ВИЧ                       Les gens qui font des gens très spéciaux,\n",
            "или находящихся в группе риска.                                ou des groupes qui sont dans le groupe,\n",
            "Эти законы капитулируют перед лицом науки,                     Ce sont des lois de la science,\n",
            "они основаны на предрассудках,                                 ils sont basés sur les prédates,\n",
            "невежестве, переписании традиций                               de la tradition\n",
            "и выборочном толковании религии.                               et la religion,\n",
            "Но знаете что? Вы не обязаны верить мне на слово.              Mais vous savez quoi ?\n",
            "Давайте послушаем истории двух человек,                        Permettez-moi de vous écouter, deux personnes\n",
            "лично столкнувшихся со вторым типом законов.                   qui ont été présentés par la deuxième loi de la loi.\n",
            "Первый из них — Ник Родес, американец.                         La première est que Niko,\n",
            "Он был осуждён по закону штата Айова                           Il a été condamné à l'ouest de l'ouest de l'ouest\n",
            "за распространение и передачу ВИЧ.                             pour le VIH.\n",
            "В преступлениях, которых он на самом деле не совершал.         Les criminels qui ne sont pas vraiment faits.\n",
            "(Видео) Ник Родес: Если что-то противозаконно,                 (Vidéo) Nike : Si quelque chose\n",
            "общество понимает,                                             la société comprend\n",
            "что это неприемлемо, что это плохое поведение.                 c'est que ce n'est pas une mauvaise chose.\n",
            "И, я полагаю, строгость наказания                              Et je pense que la façon dont je pense\n",
            "говорит о том, насколько плох человек.                         a dit à quel point les fœtus sont importants.\n",
            "Вы — особо опасный преступник (до 60 лет заключения),          Vous êtes un crime de 60 ans,\n",
            "пожизненный насильник.                                         qui a été très forte.\n",
            "Вы — очень, очень, очень плохой человек.                       Vous êtes très, très, très mauvais que vous êtes très mauvais\n",
            "И вы совершили очень, очень, очень плохой поступок.            Et vous avez fait un problème très mauvais,\n",
            "Это просто внушается вам.                                      C'est juste un sentiment de vous.\n",
            "Вы проходите через исправительную систему,                     Vous prenez le système gouvernemental\n",
            "и каждый говорит вам об этом.                                  et tout le monde vous dit :\n",
            "И вы начинаете думать: «Да, я — плохой человек».               Et vous commencez à penser : « Oui, je suis une mauvaise chose.\n",
            "Ширин Эль-Феки: Это не просто вопрос                           Shanghai, Elic : Ce n'est pas juste une question\n",
            "несправедливых или неэффективных законов.                      ou non ?\n",
            "В некоторых странах хорошие законы.                            Dans certains pays de bonnes lois.\n",
            "Законы, способные противостоять волне ВИЧ.                     Les vagues ne peuvent pas se débarrasser du VIH.\n",
            "Проблема в том, что эти законы попираются.                     Le problème est que ces lois se sont effondrés.\n",
            "Потому что ненависть даёт неофициальное разрешение             Parce que la déteste des gens\n",
            "относиться к людям с ВИЧ                                       pour les traiter les gens\n",
            "или находящимся в группе риска                                 ou un groupe de risques\n",
            "иначе, чем к остальным гражданам.                              d'une certaine façon que les citoyens.\n",
            "Именно это случилось                                           Ce qui s'est passé\n",
            "с Хелмой и Донго из Намибии.                                   avec Humby et Jumbi.\n",
            "(Видео) Хилма: Я узнала,                                       (Vidéo) Henry : J'ai appris\n",
            "когда пошла в больницу для осмотра во время беременности.      quand je suis allée à un hôpital.\n",
            "Медсестра сказала, что каждая беременная женщина               Une infirmière a dit que chaque femme est enceinte\n",
            "должна также пройти в тот же день тест на ВИЧ.                 il doit aussi y avoir un test au VIH.\n",
            "Я прошла, и результат оказался положительным.                  Je me suis rendue compte que le résultat était positif.\n",
            "В тот день я узнала.                                           Et ce jour-là.\n",
            "Медсестра сказала мне: «Зачем вам рожать,                      Et ma sœur m'a dit : « Pourquoi tu t'es\n",
            "если вы знаете, что инфицированы ВИЧ?                          si vous êtes infecté ?\n",
            "Почему ты беременна, если ты ВИЧ-положительна?»                Pourquoi vous êtes enceinte ?\n",
            "Я уверена, что они стерилизовали меня именно по этой причине.  Je suis sûre qu'ils me détruisaient cette raison pour cela.\n",
            "Потому что я была ВИЧ-инфицирована.                            Parce que j'étais VIH.\n",
            "Они не дали мне документы,                                     Ils ne m'ont pas donné des papiers\n",
            "не объяснили, что в них было.                                  ne l'ont pas expliqué ce qu'ils ont fait.\n",
            "Сестра просто пришла с ними,                                   Et Sebastit est venu\n",
            "уже отметив, где я должна подписать.                           depuis que je devais écrire.\n",
            "И, во время схваток,                                           Et pendant que je vais vous emmener\n",
            "у меня не было сил попросить прочитать их мне.                 et je n'avais pas de chance de lire mes livres.\n",
            "Я просто подписала.                                            J'ai juste écrit.\n",
            "Хилма, Ник и наш человек из королевства относятся              Hill, Nick et notre personne ne comprend\n",
            "к 34 миллионам людей, инфицированных ВИЧ,                      à 34 millions de personnes infectées par le VIH,\n",
            "согласно последним оценкам.                                    selon le dernier point de vue.\n",
            "Они — счастливчики,                                            Ils sont heureux.\n",
            "потому что до сих пор живы.                                    parce que c'est toujours vrai.\n",
            "Согласно тем же оценкам,                                       De même, les valeurs\n",
            "в 2010 году 1,8 миллиона человек скончались                    en 2010,\n",
            "от болезней, связанных со СПИДом.                              des maladies du SIDA.\n",
            "Это ужасные и трагические цифры.                               Ce sont des nombres terribles.\n",
            "Но если мы посмотрим на статистику более широко,               Mais si nous regardons les statistiques plus profondes,\n",
            "то увидим причины для надежды.                                 vous pouvez voir la raison pour laquelle vous pouvez le voir.\n",
            "Число новых заражений ВИЧ в мире снижается.                    Il y a des nouveaux infections dans le monde.\n",
            "В мировом масштабе                                             Dans le monde,\n",
            "число смертей также начинает снижаться.                        le nombre de décès commence à se reproduire.\n",
            "Многие причины положили начало этим тенденциям,                Beaucoup de raisons ont été le début\n",
            "но самая значительная из них заключается                       mais le plus important,\n",
            "в увеличении по всему миру количества людей,                   dans le monde entier\n",
            "получающих антиретровирусную терапию,                          avec des antiangiogéniques\n",
            "препараты, необходимые для сдерживания ВИЧ.                    des médicaments nécessaires pour le VIH.\n",
            "Но проблемы всё ещё остаются.                                  Mais le problème est toujours différente.\n",
            "Сейчас только половина людей, нуждающихся в лекарствах,        Ce n'est que la moitié des gens qui ont besoin\n",
            "получает их.                                                   on leur donne\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
