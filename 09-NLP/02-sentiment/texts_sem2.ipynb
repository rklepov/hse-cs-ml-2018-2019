{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в анализ текстов: классификация\n",
    "\n",
    "-------------------------------\n",
    "\n",
    "На сегодняшней паре мы будем с вами обучать на текстах свой собственный классификатор. \n",
    "\n",
    "\n",
    "##  Анализ тональности общественного мнения\n",
    "\n",
    "Давайте попробуем сделать что-нибудь прикольное! Например, проанализировать общественное мнение по поводу чего-нибудь. Одним из способов анализа общественного мнения является анализ тональности Twitter по нескольким релевантным хэштегам. Например, вот в [этой статье на Хабре](https://habr.com/company/dca/blog/274027/) пацаны пытались проанализировать динамику общественного мнения о новом эпизоде звёздных войн. \n",
    "\n",
    "Попробуем сделать что-то похожее. Для этого возьмём из интернета [готовую разметку твиттера](http://study.mokoron.com) на положительный и отрицательный сентимент-окрас твиттов. На основе этой разметки мы обучим свою собственную модель для классификации твиттов, а после будем применять её. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # для таблиц\n",
    "import numpy as np   # для матриц\n",
    "\n",
    "# визуализация \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "##########################################################\n",
    "# Любые ваши библиотеки, которые могли бы нам помочь! ####\n",
    "##########################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Данные\n",
    "\n",
    "Подгрузим данные и полюбуемся на них. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226834, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  @first_timee хоть я и школота, но поверь, у на...       1\n",
       "1  Да, все-таки он немного похож на него. Но мой ...       1\n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...       1\n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...       1\n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg = pd.read_csv('twitter_datasets/negative.csv', sep=';',header=-1)\n",
    "df_pos = pd.read_csv('twitter_datasets/positive.csv', sep=';',header=-1)\n",
    "\n",
    "df = df_pos[[3,4]].append(df_neg[[3,4]])\n",
    "df.columns = ['text', 'target']\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.target = df.target.replace({-1:0})\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом столбце тексты твиттов. Во втором столбце две метки: либо $1$, если твит позитивный, либо $0$, если твит негативный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Люблю маму и папу!!!!а в остальное я так...-влюбляюсь, привязываюсь)))\\xa0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[10]  # пример позитива"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ivanenko14 и у меня также, только будильник еще и не выключался.. папу разбудила ('"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[-10] # пример негатива"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Предобработка данных \n",
    "\n",
    "Начнём с предобработки данных. Напишем для этого классную функцию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text, stop = stopwords, tokenizer = tokenizer):\n",
    "    \"\"\" \n",
    "    Возвращает тексты: \n",
    "        * лемматизированные,\n",
    "        * без стоп-слов, \n",
    "        * в нижнем регистре, \n",
    "        * все слова длиннее 3 символов\n",
    "\n",
    "    text: string\n",
    "        Текст поста\n",
    "\n",
    "    parameters: list \n",
    "        stop: список из стоп-слов, example: ['а', политик', 'выбирать']\n",
    "        tokenizer: токенизатор для текста, поданного на вход\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ваш код, не забудьте привести все тексты к нижнему регистру\n",
    "    # Перед функцией подгрузите все необходимые библиотеки\n",
    "    \n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убедитесь на нескольких примерах, что ваша функция работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Если ты это читаешь, у тебя всё работает. Если не работает, прекрати читать! \n",
    "\n",
    "Теперь давайте запустим предобработчик на всём нашем корпусе из текстов. Лемматизатор обычно работает довольно долго. Если корпус из текстов на вход идёт довольно большой, приходится паралелить вычисления. Тут мы именно это и сделаем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотека для распараллеливания кода\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "texts = df.text.get_values() \n",
    "\n",
    "n_jobs = -1 # параллелим на все ядра \n",
    "texts_lemm = Parallel(n_jobs=n_jobs)(delayed(prepare_text)(\n",
    "    text) for text in tqdm_notebook(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на пример предобработанного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_lemm[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_lemm[-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Первые модели\n",
    "\n",
    "Разбьём выборку на тренировочную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "texts_train, texts_test, X_train, X_test, \\\n",
    "y_train, y_test = train_test_split(texts, texts_lemm, df.target.get_values(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаём из зашагников `CountVectorizer` и обучаем первый вариант модели. Будем выстраивать обучение в виде пайалайна. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Собираем модель из двух шагов (cv - count_vectorizer)\n",
    "model_cv = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('classifier', LogisticRegression(C=1))\n",
    "            ])\n",
    "\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поизучаем разные куски нашей получившейся модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = \n",
    "\n",
    "# имена фичей\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "\n",
    "# смотрим на размерность словаря и ужасаемся \n",
    "print(len(count_vectorizer.vocabulary_), \"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество получившегося прогноза и итоговые коэффициенты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут подгрузить мои пиздатые функции из резервного файлика "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем обучить такую же модель но на текстах без предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем модель из двух шагов (cv - count_vectorizer)\n",
    "model_noprepe = Pipeline([\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('classifier', LogisticRegression(C=1))\n",
    "            ])\n",
    "\n",
    "model_noprepare.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cравниваем модели на качество между собой моей пиздатой картинкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Пытаемся улучшить модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1:** Модель вышла не самой удачной. Давайте попробуем обучить точно такую же модель, но с tf-idf векторизацией. Отфильтруем из векторайзера все очень частые и редкие слова так, чтобы фичей осталось не очень много. На самом деле параметры для фильтрации это гипер-параметры и их тоже можно подбирать в ходе поиска по решётке. Также как и силу регуляризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваша tf-idf модель, которая побила предыдущую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуйте добавить в модель в рамках tf-idf биграммы. Приводит ли это к улучшению модели? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваша tf-idf модель c биграммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте топ-10 положительных коэффициентов и топ-10 отрицательных. Логичные ли получились коэффициенты? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Новый пайплайн\n",
    "\n",
    "На лекции мы с вами выяснили, что главная беда анализа текстов - высокая размерность матрицы термы-на-документы. Давайте попробуем эту беду побороть. Для этого вспомним метод главных компонент, который позволяет сжать пространство высокой размерность во что-то более маленькое и приятное. Используйте для сжатия `TruncatedSVD`. Это реализация PCA, которая работает для разряженных матриц. Нужно добавить SVD в наш вычислительный пайплайн в качестве отдельного шага. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Применяем модель.\n",
    "\n",
    "Выбирете лучшую из своих моделей. Сейчас мы попытаемся применить её на практике. Делай раз. Подбираем порог для позитива и негатива. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делай два. Подгружаем новую табличку с твиттами и прогоняем по ней нашу модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_prepare(path, model=model):\n",
    "\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[['Tweets', 'Date']]\n",
    "\n",
    "    # предобработали дату\n",
    "    df.Date = df.Date.apply(lambda x: x.split(' ')[2] + ' ' \n",
    "                        + x.split(' ')[1] + ' ' + x.split(' ')[-1])\n",
    "\n",
    "    # по очереди применяем все предобрабатывающие функции\n",
    "    df['prepareTweets'] = df.Tweets.apply(prepare_text)\n",
    "\n",
    "    print(\"Размер таблицы: \", df.shape)\n",
    "    # финальная предобработка (добавление нулей)\n",
    "    X = df.prepareTweets.values\n",
    "\n",
    "    # предсказываем вероятность негатива\n",
    "    prob = model.predict_proba(X)[:,-1]\n",
    "    df['prob'] = prob\n",
    "    return df[['Date', 'Tweets', 'prob']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делай три. Рисуем весёлую картинку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_plot(df, cutoff_neg=0.65, cutoff_pos=0.45):\n",
    "    df['Negative'] = df.prob < cutoff_pos\n",
    "    df['Positive'] = df.prob > cutoff_neg\n",
    "    df['Neutral'] = (df.prob <= cutoff_neg) | (df.prob >= cutoff_pos)\n",
    "\n",
    "    df_abs = df[['Date', 'Positive', 'Neutral','Negative']].groupby('Date').sum()\n",
    "    df_perc = df_abs.divide(df_abs.sum(axis=1), axis=0)\n",
    "    \n",
    "    # строим красивую картинку \n",
    "    plt.figure(figsize=(14,6))\n",
    "\n",
    "    # colors: https://www.color-hex.com/color/2ecc71\n",
    "    pal = [\"#e74c3c\", \"#f1c40f\", \"#2ecc71\"]\n",
    "\n",
    "    plt.stackplot(df_perc.index, df_perc['Negative'],  df_perc['Neutral'], df_perc['Positive'], \n",
    "                        labels=['Negative','Neutral','Positive'],  colors=pal)\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.margins(0,0)\n",
    "    plt.title('Доли твитов определённой тональности',size=18)\n",
    "    plt.show()\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поихали. \n",
    "\n",
    "### Что люди пишут в твиттере о кино?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rapsodia = table_prepare('twitter_datasets/df_film_rapsodia.csv')\n",
    "df_rapsodia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_plot(df_rapsodia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fantastic = table_prepare('twitter_datasets/df_film_fantastic.csv')\n",
    "df_fantastic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_plot(df_fantastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример позитива\n",
    "df_fantastic[df_fantastic.prob > 0.9].Tweets.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример негатива\n",
    "df_fantastic[df_fantastic.prob < 0.1].Tweets.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что люди пишут в твиттере о банках?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sber = table_prepare('twitter_datasets/df_sber.csv')\n",
    "df_sber.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_plot(df_sber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tinkoff = table_prepare('twitter_datasets/df_tinkoff.csv')\n",
    "df_tinkoff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_plot(df_tinkoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что люди пишут в твиттере о рэпе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basta = table_prepare('df_basta.csv')\n",
    "df_basta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_plot(df_basta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noize = table_prepare('df_noize.csv')\n",
    "df_noize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_plot(df_noize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oxxy = table_prepare('df_oxxy.csv')\n",
    "df_oxxy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_plot(df_oxxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваши идеи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Эксперименты с деревьями \n",
    "\n",
    "На лекции мы обсудили, что деревья, будстинг и тп не очень заходят для решения задач, связаннх с текстами. Давайте убедимся, что они и правда работают хуже. Для экспериментов возьмём небольшой кусочек от базовой выборки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пришло време деревьев. Подгружаем классифайер для случайного леса и бустинг. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберите два пайплайна: `CountVectorizer() -> TruncatedSVD(100) -> Randomforest(100)` и такой же с бустингом. Насколько высоким оказывается качество? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличьте количество компонент и деревьев до $1000$. Стало ли лучше? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте взять в качестве векторайзера tf-idf. Удалось ли улучшить результат? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите лучшую модель с деревьями. Бьёт ли она результаты вашей лучшей регрессии? Почему при сопостовимом качестве моделей имеет смысл остановиться на регрессии и не трогать деревья? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.  Наивный байес \n",
    "\n",
    "Иногда одним из самых первых алгоритмов, среди натравливаемых на тексты на равне с логистической регрессией, оказывается наивный байесовский классификатор. \n",
    "\n",
    "Требуется оценить вероятность принадлежности документа $d \\in D$ классу $c \\in C$: $p(c|d)$. Каждый документ –  мешок слов, всего слов $|V|$.\n",
    "\t\n",
    "* $p(c)$ – априорная вероятность класса $c$\n",
    "* $p(c|d)$ – апостериорная вероятность класса $c$\n",
    "* $ p(c|d) = \\frac{p(d|c)p(c)}{p(d)} $\n",
    "\n",
    "\n",
    "В мультиномиальной байесовской модели документ – это последовательность событий. Каждое событие – этослучайный выбор одного слова из мешка слов. Когда мы подсчитываем правдоподобие документа, мы перемножаем вероятности того, что мы достали из мешка те самые слова, которые встретились в документе. \n",
    "\n",
    "Наивное предположение в том, что мы достаём из мешка разные слова независимо друг от друга, т.е. вероятности признаков внутри класса независимы.\n",
    "\n",
    "Получается мультиномиальная генеративная модель, которая учитывает количество повторений каждого слова, но не учитывает порядок этих слов, а также каких слов нет в документе.\n",
    "\n",
    "* [Подробнее о различных видах байесовских классификаторов](https://logic.pdmi.ras.ru/~sergey/teaching/mlaptu11/03-classifiers.pdf).\n",
    "* [Слайды Дмитрия Игнатова про классификацию](https://cs.hse.ru/data/2016/04/13/1129765566/Classification.pdf)\n",
    "\n",
    "-------------------------\n",
    "\n",
    "Давайте попробуем обучить наивную Байесовскую модель. Сделаем это точно также, как и с предыдущими моделями, в виде пайплайна. В качестве первого шага пайплайна попробуйте оба векторайзера по очереди. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Сравниваем всё, что намоделировали!\n",
    "\n",
    "Постройте все получившиеся precision-recall кривые на одной картинке. Какая самая классная f-мера получилась? Имейте в виду, что разметка твиттера, которой мы пользуемся, была сделана в полуавтоматическом режиме. Сама автор разметки оценивает её качество на уровне 80%. Выборка сбалансированная. Обычно получается, что accuracy на ней в районе $0.75$. Если вы добрались до такой отметины, ваша модель хороша. Если вы пробили 0.8, то вы умудрились оверфитнутся. Поздравляю. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось время? (маловероятно). Тогда попробуем трюк с хэшированием м обсудим, почему, на мой взгляд, его никогда не надо пробовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://hsto.org/webt/gw/-l/bs/gw-lbsso67kzbcmb8oibvw-pn1u.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
