{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача идентификации взломщика по его поведению в сети Интернет\n",
    "\n",
    "Ссылка: [Catch Me If You Can](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2)\n",
    "\n",
    "У нас есть данные по посещениям пользователями каких-то сайтов и времени посещения.\n",
    "\n",
    "Необходимо определить сессии в тесте, которые осуществил определенный юзер. Его класс в трейне 1, все остальные юзеры 0.\n",
    "\n",
    "В ноутбуке приведен алгоритм создания спарс матрицы из сайтов, которые посещали люди из выборки. В каждой строке будет от 1 до 10 непустых элементов.\n",
    "\n",
    "По времени никаких фич не построено, это для самостоятельной работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/Alice/train_sessions.csv')\n",
    "test = pd.read_csv('../data/Alice/test_sessions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запоминаем индекс для последующего разделения трейна и теста\n",
    "idx_split = data.shape[0]\n",
    "#объединяем трейн и тест. Создание спарс матрицы в таком, как у нас, виде особо не ликует.\n",
    "data = data.append(test, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in data.columns if data[col].dtype=='int64' or\n",
    "                                           data[col].dtype=='float64']\n",
    "num_cols.remove('target')\n",
    "time_cols = [col for col in data.columns if data[col].dtype=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in time_cols:\n",
    "    data[col] = pd.to_datetime(data[col], yearfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполним отсутствующие сайты уникальным значением.\n",
    "data[num_cols] = data[num_cols].fillna(-1)\n",
    "#Это необходимо для того, чтобы данные по сайтам привести к целочисленному типу.\n",
    "data[num_cols] = data[num_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [col for col in data.columns if col.startswith('site')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Этой функцией создаем словарь посещенных юзерами сайтов\n",
    "def find_sites(li):\n",
    "    lli = {}\n",
    "    for l in li:\n",
    "        if l > 0:\n",
    "            if l in lli:\n",
    "                lli[str(l)] += 1\n",
    "            else:\n",
    "                lli[str(l)] = 1\n",
    "    return lli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['all_sites'] = data[sites].apply(find_sites, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Считаем, сколько всего сайтов было пройдено за сессию\n",
    "data['len_sites'] = data['all_sites'].apply(lambda x: sum(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для скорости создаем лист из наших словарей\n",
    "sp_list = list(data['all_sites'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем пустую спарс матрицу и задаем ее размер с запасом\n",
    "site1 = lil_matrix((data.shape[0], 100000))#, dtype=np.int8)\n",
    "row = 0\n",
    "\n",
    "#в цикле идем по каждой строке и ставим единичку в ту колонку, сайт которой есть в строке\n",
    "for s in sp_list:\n",
    "    for key, value in s.items():\n",
    "        site1[row, key] = 1\n",
    "    row+=1\n",
    "\n",
    "#убираем лишние нулевые колонки\n",
    "site1 = site1.tocsc()[:, np.where(site1.getnnz(axis=0) > 0)[0]].tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#размер нашего спарса\n",
    "site1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#в данной ячейке мы удаляем все колонки с нулевыми значениями в колонках теста \n",
    "#и здесь мы ликуем, надеясь, что это даст выше скор\n",
    "ttest = site1[idx_split:]\n",
    "site1 = site1.tocsc()[:, np.where((ttest.getnnz(axis=0) > 0))[0]].tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делим снова на тест и трейн\n",
    "ttest = site1[idx_split:]\n",
    "site1 = site1[:idx_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучаем с кросс-валидацией линейную регрессию\n",
    "#предсказываем 10 раз трейн, дальше усредним\n",
    "answ = []\n",
    "v_metric = []\n",
    "\n",
    "n=1\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=777)   \n",
    "for tr_ind, val_ind in kf.split(site1):\n",
    "    print('Start {} fold'.format(n))\n",
    "\n",
    "    val = site1[val_ind]\n",
    "    ttt = site1[tr_ind] \n",
    "\n",
    "    start_time = time.time()\n",
    "    clf = LogisticRegression(C=2, solver='lbfgs', max_iter=1000,\n",
    "                            random_state=777)\n",
    "\n",
    "    clf.fit(ttt, data['target'][tr_ind].reset_index(drop=True)) \n",
    "\n",
    "    model_pred_valid = clf.predict_proba(val)[:, 1]\n",
    "\n",
    "    y_valid = data['target'][val_ind].reset_index(drop=True)\n",
    "    valid_metric = auc(y_valid, model_pred_valid)\n",
    "    v_metric.append(valid_metric)\n",
    "\n",
    "    print('fold score:', valid_metric, round((time.time() - start_time)/60, 2))\n",
    "    model_pred = clf.predict_proba(ttest)[:, 1]\n",
    "    answ.append(model_pred)\n",
    "\n",
    "    n+=1\n",
    "\n",
    "    print('crossval score:', np.mean(v_metric), 'std', np.std(v_metric))\n",
    "    print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#собираем предсказания теста\n",
    "answ_df = pd.DataFrame()\n",
    "for i in range(len(answ)):\n",
    "    answ_df['an'+str(i)] = answ[i]\n",
    "answ_df['answer'] = answ_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answ_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#пишем функцию для сабмита и делаем сабмит\n",
    "\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(answ_df['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(y_test, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
