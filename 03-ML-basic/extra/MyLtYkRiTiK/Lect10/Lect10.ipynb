{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series\n",
    "\n",
    "Стоковые данные для первого примера взяты [отсюда](https://www.kaggle.com/camnugent/sandp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удобный способ читать временные данные, когда вы знаете, что столбец даты в нужном формате\n",
    "df = pd.read_csv('../data/all_stocks_5yr.csv.zip', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Name'] == 'GOOGL'].copy().drop('Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['close'].plot(figsize=(15, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим скользящее среднее (moving average). Это можно сделать с помощью метода rolling, главное задать окну усреднения.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 day rolling mean\n",
    "df.rolling(7).mean().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['close_rolling_14'] = df['close'].rolling(window=14).mean()\n",
    "df[['close','close_rolling_14']].plot(figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample\n",
    "\n",
    "Это приведение индекса к иному формату. К квартальному, годовому и прочим. Доступные форматы сожно посмотерть по [ссылке](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases).\n",
    "\n",
    "Так как это, по сути, одна из разновидностей группировки, то надо задать математическую функцию, как объединять строки $(sum, mean, std, sem, max, min, median, first, last, ohlc)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средние квартальные данные\n",
    "df.resample(rule='Q').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем данные по объему продаж акций по кварталам\n",
    "df['volume'].resample('Q').mean().plot(kind='bar', figsize=(15, 5), color='b')\n",
    "plt.title('Quarter volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Shifting\n",
    "\n",
    "Иногда необходимо сдвигать данные вперед или назад."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вперед\n",
    "df['open_1'] = df['open'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Назад\n",
    "df['close_-1'] = df['close'].shift(-1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels\n",
    "[Statsmodels](https://www.statsmodels.org/stable/index.html) - это питоновский модуль, который содержит реализацию различных статистических моделей, а также статистические тесты и способы исследования данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_stocks_5yr.csv.zip', index_col='date', parse_dates=True)\n",
    "df = df[df['Name'] == 'GOOGL'].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск тренда\n",
    "Фильтр Hodrick-Prescott разделяет временной ряд $y_t$  на тренд  $\\tau_t$ и циклическую составляющую  $\\zeta_t$\n",
    "\n",
    "$y_t = \\tau_t + \\zeta_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_cycle, close_trend = sm.tsa.filters.hpfilter(df['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cl_cycle'] = close_cycle\n",
    "df['cl_trend'] = close_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['close', 'cl_trend']].plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск сезонной составляющей (Error, Trend, Seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(df['close'], model='multiplicative', freq=30)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cl_trend_ses'] = decomposition.trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['close', 'cl_trend', 'cl_trend_ses']].plot(figsize=(55, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['close', 'cl_trend', 'cl_trend_ses']]['2017-10-01':'2018-01-01'].plot(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially-weighted moving average \n",
    "\n",
    "Выше мы разобрали работу простого скользящего окна. Но у этого метода есть недостатки:\n",
    "* Малый размер окна ведет к большему шуму, чем сигналу;\n",
    "* Лаг относительно размера окна;\n",
    "* Некоторая потеря информаии из-за усреднения;\n",
    "* Не дает понимания о поведении в будущем, показывает только существующие тренды;\n",
    "* Экстримальные значения могут портить моделирование.\n",
    "\n",
    "Модель эксопоненциально-взвешенного скользящего среднего может исправить некоторые недостатки прошлой модели (Exponentially-weighted moving average). Она придает больший вес значениям, которые были недавно, то есть в конце рассматриваемого периода. Значения весов зависят от размера окна и параметров модели.\n",
    "\n",
    "[Полное описание модели можно найти зесь](http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows)\n",
    "\n",
    "Формула такова:\n",
    "\n",
    "### $ y_t =   \\frac{\\sum\\limits_{i=0}^t w_i x_{t-i}}{\\sum\\limits_{i=0}^t w_i} $\n",
    "\n",
    "Где $x_t$ - это входное значение ряда, $w_i$ - вес, $y_t$ - выходное значение модели.\n",
    "\n",
    "Если задать значение параметра adjust=True (default), то взвешенные средние будут считаться по следующей формуле:\n",
    "\n",
    "### $y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ...\n",
    "+ (1 - \\alpha)^t x_{0}}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ...\n",
    "+ (1 - \\alpha)^t}$\n",
    "\n",
    "Если adjust=False, то:\n",
    "\n",
    "#### $\\begin{split}y_0 &= x_0 \\\\\n",
    "y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\\end{split}$\n",
    "\n",
    "\n",
    "Значение альфы можно задать несколькими способами:\n",
    " \n",
    "* Span - аналог окна\n",
    "* Center of mass, может быть выражен через span: c=(s−1)/2\n",
    "* Период полураспада\n",
    "* Напрямую заданная альфа.\n",
    "\n",
    "Данные для дальнейшего примера [отсюда](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/air_visit_data.csv.zip', index_col='visit_date', parse_dates=True)\n",
    "df = df[df['air_store_id'] == 'air_cb7467aed805e7fe']\n",
    "df.drop('air_store_id', inplace=True, axis=1)\n",
    "df.dropna(how='any', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df, model='multiplicative', freq=30)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ewma30'] = df.ewm(span=30).mean()\n",
    "df['rol_30'] = df['visitors'].rolling(window=30).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['visitors','ewma30', 'rol_30']].plot(figsize=(35, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arima (p,d,q)\n",
    "\n",
    "## Autoregressive Integrated Moving Averages\n",
    "Модель используются при работе с временными рядами для более глубокого понимания данных или предсказания будущих точек ряда.\n",
    "\n",
    "### Параметры p,d,q\n",
    "\n",
    "* p: Кол-во лагов;\n",
    "* d: Порядок интегрированности;\n",
    "* q: Размер окна, скользящего среднего.\n",
    "\n",
    "Процесс подготовки и построения модели ARIMA\n",
    "* Подготовка и визуализация данных\n",
    "* Определение порядка интегрированности ряда и переход к стационарному ряду\n",
    "* Построение и анализ автокорреляционной и частной автокорреляционной функции\n",
    "* Построение модели\n",
    "* Оценка работоспособности модели\n",
    "* Прогнозирование с помощью модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_stocks_5yr.csv.zip', index_col='date', parse_dates=True)\n",
    "df = df[df['Name'] == 'GOOGL'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.open.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df['open'], model='multiplicative', freq=365)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(15, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест на стационарность\n",
    "\n",
    "Для теста на стационарность можно использовать [Augmented Dickey-Fuller](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test) для поиска единичного корня ([unit root test](https://en.wikipedia.org/wiki/Unit_root_test)).\n",
    "\n",
    "Нулевая гипотеза: единичный корень есть и ряд не стационарен.\n",
    "Альтернативная гипотеза: ряд стационарен.\n",
    "\n",
    "Решение можно принимать на основе p-value.\n",
    "\n",
    "* Малое значение p-value (обычно ≤ 0.05) показывает сильные доказательства против нулевой гипотезы, значит, она отвергается в пользу альтернативной.\n",
    "\n",
    "* Большое значение p-value (> 0.05) показывает слабые доказательства против нулевой гипотезы, значит, она не может быть опровергнута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_check(time_series):\n",
    "    \"\"\"\n",
    "    На вход получает временной ряд, выдает ADF репорт\n",
    "    \"\"\"\n",
    "    result = adfuller(time_series)\n",
    "    print('Augmented Dickey-Fuller Test:')\n",
    "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "\n",
    "    for value,label in zip(result,labels):\n",
    "        print(label+' : '+str(value) )\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print('------------------')\n",
    "        print(\"Сильные доказательства против нулевой гипотезы, она отвергается. \\nРяд не имеет единичного корня и является стационарным.\")\n",
    "    else:\n",
    "        print('------------------')\n",
    "        print(\"Слабые доказательства против нулевой гипотезы, она не отвергается. \\nРяд имеет единичный корень и не является стационарным.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_check(df['open'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение порядка интегрированности ряда и переход к стационарному ряду\n",
    "\n",
    "Порядок интегрированности - это сколько разностей вам надо взять, чтобы ряд стал стационарным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['open_diff1'] = df['open'] - df['open'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_check(df['open_diff1'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['open_diff1'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение и анализ автокорреляционной и частной автокорреляционной функции (ACF и PACF)\n",
    "\n",
    "График автокорреляционной ф-ии показывает корреляцию ряда со своими лагами. По оси у - значение корреляции, по оси х - номер лага. По смыслу для стационарного процесса значение автокорреляции показывает, насколько в среднем изменится сегодняшний у, если у k-периодов назад, то есть yt-k, вырос на 1.\n",
    "\n",
    "Эти графики строится по стационарным данным. Больше информации про ACF и PACF можно найти по ссылкам: [здесь](http://people.duke.edu/~rnau/arimrule.htm) и [здесь](https://people.duke.edu/~rnau/411arim3.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_first = plot_acf(df[\"open_diff1\"].dropna(), lags=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частная автокорреляционная функция\n",
    "\n",
    "Частная корреляция — это обычная корреляция между yt и yt ‒ k, только yt и yt ‒ k должны быть очищены от влияния промежуточных случайных величин: yt ‒ 1, yt ‒ 2,..., yt ‒ k + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plot_pacf(df[\"open_diff1\"].dropna(), lags =40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретация ACF и PACF\n",
    "\n",
    "* Случай А. Процесс AR(p)\n",
    "    1. ACF бесконечна по протяженности и только в пределе при k → ∞ сходится к нулю\n",
    "    2. PACF равна (или близка) к нулю для лагов, больших, чем p.\n",
    "* Случай Б. Процесс MA(q)\n",
    "    1. ACF равна (или близка) к нулю для лагов, больших, чем q.\n",
    "    2. PACF бесконечна по протяженности и только в пределе при k → ∞ сходится к нулю\n",
    "* Случай В. Если не А и не Б, то у вас ARMA(p,q)\n",
    "\n",
    "По возможности рекомендуется использовать экономичные модели: p + q ≤ 3 (если нет сезонной компоненты)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение ARIMA модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(df['open'],order=(1,1,1))\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценивание\n",
    "1. Значимость коэффициентов модели\n",
    "2. Анализ остатков модели: \n",
    "    * Остатки должны быть белым шумом\n",
    "    * Должны иметь нулевую автокорреляцию\n",
    "    * Все элементы ACF для ряда остатков должны незначимо отличатся от нуля\n",
    "3. Информационные критерии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.resid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.resid.plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.api import qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_first = plot_acf(results.resid, lags=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acorr_ljungbox(results.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "формально проверить автокорреляцию можно с помощью Ljungbox test.\n",
    "\n",
    "Нулевая гипотеза: Автокорреляция отсутствует.\n",
    "Альтернативная гипотеза: Автокорреляция присутствует.\n",
    "\n",
    "Так как у нас p-value для всех рассмотренных лагов больше 0.05, то можно сделать вывод, что нулевая гипотеза не принимается и автокорреляция отсутствует."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model = ARIMA(np.array(df['open'].dropna()), order=(1,1,1))\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results.plot_predict(start = df.shape[0]-300, end=df.shape[0], dynamic= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import DateOffset\n",
    "future_dates = [df.index[-1] + DateOffset(days=x) for x in range(0,50) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# future_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates_df = pd.DataFrame(index=future_dates[1:],columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df = pd.concat([df,future_dates_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results.plot_predict(start = future_df.shape[0]-51, end=future_df.shape[0], dynamic= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    "size = int((len(df)) * 0.95)\n",
    "train, test = df['open'][0:size], df['open'][size:len(df)]\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "    model = ARIMA(history, order=(1,2,1))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "#     print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test RMSE: %.3f' % error**(1/2))\n",
    "# plot\n",
    "plt.plot([x for x in test])\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = [x for x in test[:-1]]\n",
    "\n",
    "error = mean_squared_error(test[1:], predictions2)\n",
    "print('Test RMSE: %.3f' % error**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x for x in test[1:]])\n",
    "plt.plot(predictions2, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = mean_squared_error(test[1:], predictions[1:])\n",
    "print('Test RMSE: %.3f' % error**(1/2))\n",
    "# plot\n",
    "plt.plot([x for x in test[1:]])\n",
    "plt.plot(predictions[1:], color='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
