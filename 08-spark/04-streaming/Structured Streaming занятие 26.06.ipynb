{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [*Занятие 4*](https://hackmd.io/@J_qqq0PjTGK1be0341GpYA/BJEYLlK-X#/ \"Spark Streaming - HackMD\")\n",
    "\n",
    "https://hackmd.io/@J_qqq0PjTGK1be0341GpYA/BJEYLlK-X#/\n",
    "\n",
    "### Spark Streaming: [Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html \"Structured Streaming Programming Guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_in = \"/stream/structured/\"\n",
    "!mkdir -p $stream_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "schema = types.StructType().add(\"rank\", \"integer\").add(\"site\", \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = spark.readStream.schema(schema).csv(stream_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbatim_output = (\n",
    "    input_df\n",
    "    .writeStream\n",
    "    .trigger(processingTime=\"10 seconds\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"input2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f5dec6861d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbatim_output.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    5120|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) FROM input2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuf: write error: Broken pipe\r\n",
      "shuf: write error\r\n"
     ]
    }
   ],
   "source": [
    "!shuf /data/top-1m.csv | head -n1k > `tempfile -d $stream_in`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions\n",
    "\n",
    "agg_stream = (\n",
    "    input_df\n",
    "    .select(\n",
    "        functions.explode(\n",
    "            functions.split(\"site\", \"\\.\")\n",
    "        ).alias(\"token\")\n",
    "    )\n",
    "    .groupBy(\"token\")\n",
    "    .count()\n",
    "    .orderBy(functions.desc(\"count\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f5deb612a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    agg_stream\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .trigger(processingTime=\"10 seconds\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"tokens\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   token|count|\n",
      "+--------+-----+\n",
      "|     com| 2157|\n",
      "|     org|  243|\n",
      "|     net|  180|\n",
      "|      ru|  167|\n",
      "|      co|  164|\n",
      "|      de|  117|\n",
      "|      br|   92|\n",
      "|      uk|   77|\n",
      "|      pl|   70|\n",
      "|blogspot|   61|\n",
      "|      au|   55|\n",
      "|      in|   51|\n",
      "|      jp|   47|\n",
      "|      ir|   45|\n",
      "|      it|   43|\n",
      "|     gov|   40|\n",
      "|     edu|   37|\n",
      "|      tw|   33|\n",
      "|      cz|   33|\n",
      "|      fr|   33|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from tokens\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuf: write error: Broken pipe\r\n",
      "shuf: write error\r\n"
     ]
    }
   ],
   "source": [
    "!shuf /data/top-1m.csv | head -n1k > `tempfile -d $stream_in`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   token|count|\n",
      "+--------+-----+\n",
      "|     com| 2682|\n",
      "|     org|  306|\n",
      "|     net|  221|\n",
      "|      ru|  207|\n",
      "|      co|  202|\n",
      "|      de|  157|\n",
      "|      br|  112|\n",
      "|      uk|   98|\n",
      "|      pl|   86|\n",
      "|blogspot|   86|\n",
      "|      au|   70|\n",
      "|      in|   68|\n",
      "|      jp|   59|\n",
      "|      ir|   54|\n",
      "|      it|   54|\n",
      "|     gov|   49|\n",
      "|      fr|   49|\n",
      "|     edu|   48|\n",
      "|      cz|   39|\n",
      "|      tw|   38|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from tokens\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|         site|             ip|\n",
      "+-------------+---------------+\n",
      "|   google.com| 172.217.17.110|\n",
      "|  youtube.com| 216.58.211.110|\n",
      "| facebook.com|  157.240.20.35|\n",
      "|    baidu.com|123.125.114.144|\n",
      "|    baidu.com| 220.181.38.148|\n",
      "|wikipedia.org| 91.198.174.192|\n",
      "|       qq.com|  111.161.64.48|\n",
      "|       qq.com|  111.161.64.40|\n",
      "|   taobao.com| 140.205.94.189|\n",
      "|   taobao.com| 140.205.220.96|\n",
      "|    yahoo.com|    72.30.35.10|\n",
      "|    yahoo.com|   98.137.246.7|\n",
      "|    yahoo.com|   98.137.246.8|\n",
      "|    yahoo.com|     72.30.35.9|\n",
      "|    yahoo.com| 98.138.219.231|\n",
      "|    yahoo.com| 98.138.219.232|\n",
      "|    tmall.com| 140.205.94.193|\n",
      "|    tmall.com| 140.205.130.99|\n",
      "|   amazon.com|  176.32.98.166|\n",
      "|   amazon.com|205.251.242.103|\n",
      "+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ips_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(\"/data/ips\")\n",
    "    .withColumnRenamed(\"_c0\", \"site\")\n",
    "    .withColumnRenamed(\"_c1\", \"ip\")\n",
    ")\n",
    "\n",
    "ips_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_stream = (\n",
    "    input_df\n",
    "    .join(ips_df, on=\"site\")\n",
    "    .writeStream\n",
    "    .trigger(processingTime=\"10 seconds\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"annotated\")\n",
    "    .start()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+---------------+\n",
      "|           site|rank|             ip|\n",
      "+---------------+----+---------------+\n",
      "|         gmw.cn| 161|   111.202.12.1|\n",
      "| 45eijvhgj2.com| 172|198.134.112.241|\n",
      "| 45eijvhgj2.com| 172|198.134.112.244|\n",
      "| 45eijvhgj2.com| 172|198.134.112.243|\n",
      "| 45eijvhgj2.com| 172|198.134.112.242|\n",
      "|      orange.fr| 349|193.252.148.140|\n",
      "|      orange.fr| 349| 193.252.133.34|\n",
      "|list-manage.com| 527| 205.201.132.96|\n",
      "|milliyet.com.tr| 771| 34.249.120.252|\n",
      "|  getintopc.com|1636|130.185.250.154|\n",
      "|  letras.mus.br|1920| 177.54.157.200|\n",
      "|   malavida.com|1930| 91.192.108.161|\n",
      "|      01net.com|1947|  63.32.252.147|\n",
      "|      01net.com|1947|     52.31.29.8|\n",
      "|      01net.com|1947|   52.49.70.213|\n",
      "|  teachable.com|2290|  104.20.81.110|\n",
      "|  teachable.com|2290|  104.20.80.110|\n",
      "| tripadvisor.in|2689|192.229.162.112|\n",
      "| tripadvisor.in|2689|192.229.182.112|\n",
      "| tripadvisor.in|2689| 192.229.189.15|\n",
      "+---------------+----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from annotated\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_stream = (\n",
    "    input_df\n",
    "    .join(ips_df, on=\"site\")\n",
    "    .select(\"site\", \"ip\")\n",
    "    .groupBy(\"site\")\n",
    "    .agg(functions.collect_set(\"ip\").alias(\"ips\"))\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .trigger(processingTime=\"10 seconds\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"deduped\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                site|                 ips|\n",
      "+--------------------+--------------------+\n",
      "|           1form.com|[3.104.131.222, 1...|\n",
      "|creative-proteomi...|     [54.176.148.20]|\n",
      "|   piecesauto-pro.fr|[104.17.55.36, 10...|\n",
      "|  playspellbreak.com|[198.185.159.144,...|\n",
      "|   thepiratebay.tips|    [184.168.221.53]|\n",
      "|unionbankonline.c...|     [59.160.35.102]|\n",
      "|        webtrekk.com|    [185.102.94.245]|\n",
      "|      caibaojian.com|     [120.24.76.145]|\n",
      "|puthiyathalaimura...|[13.32.42.180, 13...|\n",
      "|        jwpepper.com|      [208.28.133.1]|\n",
      "|           rulai.org|     [130.211.240.4]|\n",
      "|         eclipse.org|     [198.41.30.198]|\n",
      "|      unlocklink.com|[104.27.191.231, ...|\n",
      "|go4worldbusiness.com|[52.4.108.53, 52....|\n",
      "|     bustyfilmes.com|[104.18.33.207, 1...|\n",
      "|           sm160.com|     [114.119.7.100]|\n",
      "|damascusuniversit...|      [178.253.95.9]|\n",
      "|      keywordkeg.com|      [78.46.165.85]|\n",
      "|       searpages.com|   [149.210.235.193]|\n",
      "|        knigolub.net|    [212.129.16.138]|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from deduped\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
