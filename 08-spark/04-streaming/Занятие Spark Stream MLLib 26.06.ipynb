{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [*Занятие 4*](https://hackmd.io/@J_qqq0PjTGK1be0341GpYA/BJEYLlK-X#/ \"Spark Streaming - HackMD\")\n",
    "\n",
    "https://hackmd.io/@J_qqq0PjTGK1be0341GpYA/BJEYLlK-X#/\n",
    "\n",
    "### Spark Streaming: ML with Streaming\n",
    "\n",
    "---\n",
    "\n",
    "Продолжение ноутбука с [*Занятия 3*](https://github.com/rklepov/hse-cs-ml-2018-2019/blob/master/08-spark/03-ml/%D0%97%D0%B0%D0%BD%D1%8F%D1%82%D0%B8%D0%B5%20MLLib%2022.06.ipynb \"Занятие MLLib 22.06.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import urllib.request\n",
    "\n",
    "import ssl\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    ZipFile.extractall(\n",
    "        ZipFile(\n",
    "            BytesIO(\n",
    "                urllib\n",
    "                .request\n",
    "                .urlopen(url,context=ctx)\n",
    "                .read()\n",
    "            )\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download('https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           1.9G        257M        864M        1.2M        823M        1.5G\r\n",
      "Swap:            0B          0B          0B\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           1.9G        385M        736M        1.2M        824M        1.4G\r\n",
      "Swap:            0B          0B          0B\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = spark.read.option(\"sep\", \"\\t\").csv(\"SMSSpamCollection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "|  ham|I'm gonna be home...|\n",
      "| spam|SIX chances to wi...|\n",
      "| spam|URGENT! You have ...|\n",
      "|  ham|I've been searchi...|\n",
      "|  ham|I HAVE A DATE ON ...|\n",
      "| spam|XXXMobileMovieClu...|\n",
      "|  ham|Oh k...i'm watchi...|\n",
      "|  ham|Eh u remember how...|\n",
      "|  ham|Fine if thats th...|\n",
      "| spam|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src = sms.withColumnRenamed(\"_c0\", \"label\").withColumnRenamed(\"_c1\", \"text\")\n",
    "src.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  ham| 4827|\n",
      "| spam|  747|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                text|              tokens|\n",
      "+-----+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|[go, until, juron...|\n",
      "|  ham|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "| spam|Free entry in 2 a...|[free, entry, in,...|\n",
      "|  ham|U dun say so earl...|[u, dun, say, so,...|\n",
      "|  ham|Nah I don't think...|[nah, i, don't, t...|\n",
      "| spam|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|  ham|Even my brother i...|[even, my, brothe...|\n",
      "|  ham|As per your reque...|[as, per, your, r...|\n",
      "| spam|WINNER!! As a val...|[winner!!, as, a,...|\n",
      "| spam|Had your mobile 1...|[had, your, mobil...|\n",
      "|  ham|I'm gonna be home...|[i'm, gonna, be, ...|\n",
      "| spam|SIX chances to wi...|[six, chances, to...|\n",
      "| spam|URGENT! You have ...|[urgent!, you, ha...|\n",
      "|  ham|I've been searchi...|[i've, been, sear...|\n",
      "|  ham|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "| spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|  ham|Oh k...i'm watchi...|[oh, k...i'm, wat...|\n",
      "|  ham|Eh u remember how...|[eh, u, remember,...|\n",
      "|  ham|Fine if thats th...|[fine, if, thats...|\n",
      "| spam|England v Macedon...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature.Tokenizer(inputCol=\"text\", outputCol=\"tokens\").transform(src).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import pipeline\n",
    "\n",
    "main = pipeline.Pipeline(\n",
    "    stages=(\n",
    "        feature.RegexTokenizer(\n",
    "            minTokenLength=3,\n",
    "            inputCol=\"text\", \n",
    "            pattern=\"\\s+\", \n",
    "            outputCol=\"tokens\",\n",
    "        ),\n",
    "        feature.CountVectorizer(\n",
    "            inputCol=\"tokens\", \n",
    "            outputCol=\"v\",\n",
    "            minDF=5,\n",
    "            maxDF=900\n",
    "        ),\n",
    "        feature.StringIndexer(inputCol=\"label\", outputCol=\"y\"),\n",
    "        classification.RandomForestClassifier(\n",
    "            seed=123,\n",
    "            labelCol=\"y\",\n",
    "            featuresCol=\"v\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+----------+\n",
      "|  y|       rawPrediction|         probability|prediction|\n",
      "+---+--------------------+--------------------+----------+\n",
      "|0.0|[17.4577708451969...|[0.87288854225984...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.6961900509745...|[0.88480950254872...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[17.5336076016230...|[0.87668038008115...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|0.0|[16.3487998720810...|[0.81743999360405...|       0.0|\n",
      "|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "+---+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = src.randomSplit(weights=(70., 30.), seed=123)\n",
    "main_model = main.fit(train)\n",
    "\n",
    "results = (\n",
    "    main_model\n",
    "    .transform(test)\n",
    "    .select(\"y\", \"rawPrediction\", \"probability\", \"prediction\")\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_in = \"/streaming/mlexample\"\n",
    "!mkdir -p $stream_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_stream = spark.readStream.schema(train.schema).option(\"sep\", \"\\t\").csv(stream_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_stream = main_model.transform(input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f5720e73048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    prediction_stream\n",
    "    .writeStream\n",
    "    .trigger(processingTime=\"10 seconds\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"preds\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+---+---+-------------+-----------+----------+\n",
      "|label|text|tokens|  v|  y|rawPrediction|probability|prediction|\n",
      "+-----+----+------+---+---+-------------+-----------+----------+\n",
      "+-----+----+------+---+---+-------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from preds\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuf: write error: Broken pipe\r\n",
      "shuf: write error\r\n"
     ]
    }
   ],
   "source": [
    "!shuf SMSSpamCollection | head -n1k > `tempfile -d $stream_in`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+---+--------------------+--------------------+----------+\n",
      "|label|                text|              tokens|                   v|  y|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+---+--------------------+--------------------+----------+\n",
      "| spam|A £400 XMAS REWAR...|[£400, xmas, rewa...|(1358,[2,5,14,19,...|1.0|[14.7228608827178...|[0.73614304413589...|       0.0|\n",
      "|  ham|Lol! U drunkard! ...|[lol!, drunkard!,...|(1358,[0,14,44,12...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|When are you goin...|[when, are, you, ...|(1358,[3,6,18,42]...|0.0|[17.6961900509745...|[0.88480950254872...|       0.0|\n",
      "|  ham|Ah poop. Looks li...|[poop., looks, li...|(1358,[4,12,22,36...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|Ü comin to fetch ...|[comin, fetch, or...| (1358,[1202],[1.0])|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|Yo! Howz u? girls...|[yo!, howz, girls...|(1358,[93,195,672...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|I have had two mo...|[have, had, two, ...|(1358,[2,4,15,19,...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|Beautiful Truth a...|[beautiful, truth...|(1358,[9,18,31,10...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|Wish i were with ...|[wish, were, with...|(1358,[10,104,148...|0.0|[16.3409103956182...|[0.81704551978091...|       0.0|\n",
      "|  ham|Are you up for th...|[are, you, for, t...|(1358,[0,2,6,25],...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|Fwiw the reason I...|[fwiw, the, reaso...|(1358,[0,1,7,11,1...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|            My phone|             [phone]|   (1358,[78],[1.0])|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|Prepare to be ple...|[prepare, pleasured]|        (1358,[],[])|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|I liked your new ...|[liked, your, new...|(1358,[3,46,388],...|0.0|[16.4617729102384...|[0.82308864551192...|       0.0|\n",
      "|  ham|Well you told oth...|[well, you, told,...|(1358,[99,175,858...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "| spam|Todays Voda numbe...|[todays, voda, nu...|(1358,[4,5,6,59,7...|1.0|[12.6319528864920...|[0.63159764432460...|       0.0|\n",
      "|  ham|So dont use hook ...|[dont, use, hook,...|(1358,[20,49,50,2...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "| spam|Hey Boys. Want ho...|[hey, boys., want...|(1358,[1,14,30,32...|1.0|[15.3681644019243...|[0.76840822009621...|       0.0|\n",
      "|  ham|Ha... Both of us ...|[ha..., both, doi...|(1358,[9,11,24,74...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "|  ham|Dont you have mes...|[dont, you, have,...|(1358,[4,49,117,4...|0.0|[17.9915243908026...|[0.89957621954013...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+---+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from preds\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
